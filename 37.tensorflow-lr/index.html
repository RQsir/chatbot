



<!DOCTYPE html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
      
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="en">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-0.17.2, mkdocs-material-2.2.5">
    
    
      
        <title>三十七-tensorflow中的线性回归 - 自己动手做聊天机器人</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/application.bcabdff3.css">
      
        <link rel="stylesheet" href="../assets/stylesheets/application-palette.792431c1.css">
      
    
    
      <script src="../assets/javascripts/modernizr.1aa3b519.js"></script>
    
    
      
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
      <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
    
    
    
  </head>
  
    
    
    
      <body data-md-color-primary="indigo" data-md-color-accent="indigo">
    
  
    <svg class="md-svg">
      <defs>
        
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="drawer">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="search">
    <label class="md-overlay" data-md-component="overlay" for="drawer"></label>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href=".." title="自己动手做聊天机器人" class="md-header-nav__button md-logo">
          
            <i class="md-icon"></i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            
              <span class="md-header-nav__topic">
                自己动手做聊天机器人
              </span>
              <span class="md-header-nav__topic">
                三十七-tensorflow中的线性回归
              </span>
            
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          
            <label class="md-icon md-icon--search md-header-nav__button" for="search"></label>
            
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="search"></label>
  <div class="md-search__inner">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" required placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query">
      <label class="md-icon md-search__icon" for="search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset">&#xE5CD;</button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
          
        
      </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="drawer">
    <span class="md-nav__button md-logo">
      
        <i class="md-icon"></i>
      
    </span>
    自己动手做聊天机器人
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href=".." title="概述" class="md-nav__link">
      概述
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../1.knowledge/" title="一-涉及知识" class="md-nav__link">
      一-涉及知识
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../2.nltk/" title="二-初识NLTK库" class="md-nav__link">
      二-初识NLTK库
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../3.corpus/" title="三-语料与词汇资源" class="md-nav__link">
      三-语料与词汇资源
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../4.pos-tagging/" title="四-自动化词性标注" class="md-nav__link">
      四-自动化词性标注
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../5.text-classification/" title="五-文本分类" class="md-nav__link">
      五-文本分类
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../6.extract/" title="六-结构化提取" class="md-nav__link">
      六-结构化提取
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../7.grammar/" title="七-文法分析" class="md-nav__link">
      七-文法分析
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../8.nlp-review/" title="八-自然语言处理" class="md-nav__link">
      八-自然语言处理
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../9.chatbot/" title="九-聊天机器人怎么做" class="md-nav__link">
      九-聊天机器人怎么做
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../10.pos-ke/" title="十-词性标注与关键词提取" class="md-nav__link">
      十-词性标注与关键词提取
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../11.storage/" title="十一-0字节存储海量语料资源" class="md-nav__link">
      十一-0字节存储海量语料资源
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../12.semantic-dependency/" title="十二-用语言云分析依存句法和语义依存" class="md-nav__link">
      十二-用语言云分析依存句法和语义依存
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../13.linguistic-model/" title="十三-探究语言模型" class="md-nav__link">
      十三-探究语言模型
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../14.participles-art/" title="十四-探究中文分词" class="md-nav__link">
      十四-探究中文分词
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../15.probabilistic-model/" title="十五-概率图模型" class="md-nav__link">
      十五-概率图模型
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../16.bag-material/" title="十六-自然语言处理中的囊中取物" class="md-nav__link">
      十六-自然语言处理中的囊中取物
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../17.specific-mehtod/" title="十七-词性自动标注" class="md-nav__link">
      十七-词性自动标注
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../18.tree/" title="十八-生成句法分析树" class="md-nav__link">
      十八-生成句法分析树
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../19.understand/" title="十九-机器人是怎么理解“日后再说”的" class="md-nav__link">
      十九-机器人是怎么理解“日后再说”的
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../20.pos-base-method/" title="二十-语义角色标注" class="md-nav__link">
      二十-语义角色标注
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../21.tf-idf/" title="二十一-隐含语义索引模型" class="md-nav__link">
      二十一-隐含语义索引模型
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../22.artificial-neural-network/" title="二十二-人工神经网络" class="md-nav__link">
      二十二-人工神经网络
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../23.cnn/" title="二十三-用CNN做深度学习" class="md-nav__link">
      二十三-用CNN做深度学习
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../24.nlp-deep-learning/" title="二十四-将深度学习应用到NLP" class="md-nav__link">
      二十四-将深度学习应用到NLP
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../25.word2vec/" title="二十五-word2vec的实现原理" class="md-nav__link">
      二十五-word2vec的实现原理
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../26.rnn/" title="二十六-递归神经网络(RNN)" class="md-nav__link">
      二十六-递归神经网络(RNN)
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../27.auto-faq/" title="二十七-自动问答" class="md-nav__link">
      二十七-自动问答
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../28.subtitle-corpus/" title="二十八-基于美剧字幕的聊天语料库建设" class="md-nav__link">
      二十八-基于美剧字幕的聊天语料库建设
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../29.corpus-1g/" title="二十九-近1GB的三千万聊天语料" class="md-nav__link">
      二十九-近1GB的三千万聊天语料
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../30.tiny-rabbit/" title="三十-第一版聊天机器人小二兔" class="md-nav__link">
      三十-第一版聊天机器人小二兔
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../31.directive/" title="三十一-把网站流量导向小二兔" class="md-nav__link">
      三十一-把网站流量导向小二兔
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../32.word-vector/" title="三十二-用影视剧字幕语料库生成词向量" class="md-nav__link">
      三十二-用影视剧字幕语料库生成词向量
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../33.lstm-rnn/" title="三十三-LSTM-RNN—有记忆的神经网络" class="md-nav__link">
      三十三-LSTM-RNN—有记忆的神经网络
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../34.torch/" title="三十四-深度学习框架torch" class="md-nav__link">
      三十四-深度学习框架torch
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../35.lstm-learning/" title="三十五-一学会甄嬛体" class="md-nav__link">
      三十五-一学会甄嬛体
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../36.tensorflow-session-graph/" title="三十六-tensorflow的session和graph" class="md-nav__link">
      三十六-tensorflow的session和graph
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="toc">
    
    
    <a href="./" title="三十七-tensorflow中的线性回归" class="md-nav__link md-nav__link--active">
      三十七-tensorflow中的线性回归
    </a>
    
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../38.make-chatbot/" title="三十八-聊天机器人构建流程" class="md-nav__link">
      三十八-聊天机器人构建流程
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../39.gpu-server/" title="三十九-搭建一台GPU共享云服务" class="md-nav__link">
      三十九-搭建一台GPU共享云服务
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../40.video-knowledge-point/" title="四十-视频之开篇宣言与知识点" class="md-nav__link">
      四十-视频之开篇宣言与知识点
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../41.video-python/" title="四十一-视频之环境搭建与python基础" class="md-nav__link">
      四十一-视频之环境搭建与python基础
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../42.practice/" title="四十二-从理论到实践开发聊天机器人1" class="md-nav__link">
      四十二-从理论到实践开发聊天机器人1
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../43.practice2/" title="四十三-从理论到实践开发聊天机器人2" class="md-nav__link">
      四十三-从理论到实践开发聊天机器人2
    </a>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                  <h1>三十七-tensorflow中的线性回归</h1>
                
                <p>用梯度下降求解线性回归问题是tensorflow最简单的入门例子（10行关键代码），本节结合上一节讲到的tensorflow中的graph来更加形象地了解tensorflow中的线性回归工作原理 </p>
<p>10行关键代码实现的线性回归</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># -*- coding: utf-8 -*-</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>

<span class="c1"># 随机生成1000个点，围绕在y=0.1x+0.3的直线周围</span>
<span class="n">num_points</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">vectors_set</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">num_points</span><span class="p">):</span>
    <span class="n">x1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.55</span><span class="p">)</span>
    <span class="n">y1</span> <span class="o">=</span> <span class="n">x1</span> <span class="o">*</span> <span class="mf">0.1</span> <span class="o">+</span> <span class="mf">0.3</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">)</span>
    <span class="n">vectors_set</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">x1</span><span class="p">,</span> <span class="n">y1</span><span class="p">])</span>

<span class="c1"># 生成一些样本</span>
<span class="n">x_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">vectors_set</span><span class="p">]</span>
<span class="n">y_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">vectors_set</span><span class="p">]</span>


<span class="c1"># 生成1维的W矩阵，取值是[-1,1]之间的随机数</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_uniform</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;W&#39;</span><span class="p">)</span>
<span class="c1"># 生成1维的b矩阵，初始值是0</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">)</span>
<span class="c1"># 经过计算得出预估值y</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">W</span> <span class="o">*</span> <span class="n">x_data</span> <span class="o">+</span> <span class="n">b</span>

<span class="c1"># 以预估值y和实际值y_data之间的均方误差作为损失</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_data</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;loss&#39;</span><span class="p">)</span>
<span class="c1"># 采用梯度下降法来优化参数</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">GradientDescentOptimizer</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
<span class="c1"># 训练的过程就是最小化这个误差值</span>
<span class="n">train</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">)</span>

<span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>
<span class="c1"># 输出图结构</span>
<span class="c1">#print sess.graph_def</span>

<span class="n">init</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">initialize_all_variables</span><span class="p">()</span>
<span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>

<span class="c1"># 初始化的W和b是多少</span>
<span class="k">print</span> <span class="s2">&quot;W =&quot;</span><span class="p">,</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">W</span><span class="p">),</span> <span class="s2">&quot;b =&quot;</span><span class="p">,</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">b</span><span class="p">),</span> <span class="s2">&quot;loss =&quot;</span><span class="p">,</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="c1"># 执行20次训练</span>
<span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="mi">20</span><span class="p">):</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
    <span class="c1"># 输出训练好的W和b</span>
    <span class="k">print</span> <span class="s2">&quot;W =&quot;</span><span class="p">,</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">W</span><span class="p">),</span> <span class="s2">&quot;b =&quot;</span><span class="p">,</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">b</span><span class="p">),</span> <span class="s2">&quot;loss =&quot;</span><span class="p">,</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="c1"># 生成summary文件，用于tensorboard使用</span>
<span class="n">writer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">SummaryWriter</span><span class="p">(</span><span class="s2">&quot;./tmp&quot;</span><span class="p">,</span> <span class="n">sess</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<p>整个收敛过程可以从输出结果中看出：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">W</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.67839384</span><span class="p">]</span> <span class="n">b</span> <span class="o">=</span> <span class="p">[</span> <span class="mf">0.</span><span class="p">]</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">0.293898</span>
<span class="n">W</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.41792655</span><span class="p">]</span> <span class="n">b</span> <span class="o">=</span> <span class="p">[</span> <span class="mf">0.30027848</span><span class="p">]</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">0.0907883</span>
<span class="n">W</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.24463286</span><span class="p">]</span> <span class="n">b</span> <span class="o">=</span> <span class="p">[</span> <span class="mf">0.30015084</span><span class="p">]</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">0.0407606</span>
<span class="n">W</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.12923941</span><span class="p">]</span> <span class="n">b</span> <span class="o">=</span> <span class="p">[</span> <span class="mf">0.30006593</span><span class="p">]</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">0.0185783</span>
<span class="n">W</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.05240078</span><span class="p">]</span> <span class="n">b</span> <span class="o">=</span> <span class="p">[</span> <span class="mf">0.30000937</span><span class="p">]</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">0.00874262</span>
<span class="n">W</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.00123519</span><span class="p">]</span> <span class="n">b</span> <span class="o">=</span> <span class="p">[</span> <span class="mf">0.29997173</span><span class="p">]</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">0.00438147</span>
<span class="n">W</span> <span class="o">=</span> <span class="p">[</span> <span class="mf">0.03283515</span><span class="p">]</span> <span class="n">b</span> <span class="o">=</span> <span class="p">[</span> <span class="mf">0.29994667</span><span class="p">]</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">0.00244773</span>
<span class="n">W</span> <span class="o">=</span> <span class="p">[</span> <span class="mf">0.05552204</span><span class="p">]</span> <span class="n">b</span> <span class="o">=</span> <span class="p">[</span> <span class="mf">0.29992998</span><span class="p">]</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">0.00159031</span>
<span class="n">W</span> <span class="o">=</span> <span class="p">[</span> <span class="mf">0.07062886</span><span class="p">]</span> <span class="n">b</span> <span class="o">=</span> <span class="p">[</span> <span class="mf">0.29991883</span><span class="p">]</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">0.00121013</span>
<span class="n">W</span> <span class="o">=</span> <span class="p">[</span> <span class="mf">0.08068825</span><span class="p">]</span> <span class="n">b</span> <span class="o">=</span> <span class="p">[</span> <span class="mf">0.29991144</span><span class="p">]</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">0.00104155</span>
<span class="n">W</span> <span class="o">=</span> <span class="p">[</span> <span class="mf">0.08738664</span><span class="p">]</span> <span class="n">b</span> <span class="o">=</span> <span class="p">[</span> <span class="mf">0.29990652</span><span class="p">]</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">0.000966807</span>
<span class="n">W</span> <span class="o">=</span> <span class="p">[</span> <span class="mf">0.09184699</span><span class="p">]</span> <span class="n">b</span> <span class="o">=</span> <span class="p">[</span> <span class="mf">0.29990324</span><span class="p">]</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">0.000933665</span>
<span class="n">W</span> <span class="o">=</span> <span class="p">[</span> <span class="mf">0.09481706</span><span class="p">]</span> <span class="n">b</span> <span class="o">=</span> <span class="p">[</span> <span class="mf">0.29990104</span><span class="p">]</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">0.00091897</span>
<span class="n">W</span> <span class="o">=</span> <span class="p">[</span> <span class="mf">0.09679478</span><span class="p">]</span> <span class="n">b</span> <span class="o">=</span> <span class="p">[</span> <span class="mf">0.29989958</span><span class="p">]</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">0.000912454</span>
<span class="n">W</span> <span class="o">=</span> <span class="p">[</span> <span class="mf">0.09811172</span><span class="p">]</span> <span class="n">b</span> <span class="o">=</span> <span class="p">[</span> <span class="mf">0.29989862</span><span class="p">]</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">0.000909564</span>
<span class="n">W</span> <span class="o">=</span> <span class="p">[</span> <span class="mf">0.09898864</span><span class="p">]</span> <span class="n">b</span> <span class="o">=</span> <span class="p">[</span> <span class="mf">0.29989797</span><span class="p">]</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">0.000908283</span>
<span class="n">W</span> <span class="o">=</span> <span class="p">[</span> <span class="mf">0.09957258</span><span class="p">]</span> <span class="n">b</span> <span class="o">=</span> <span class="p">[</span> <span class="mf">0.29989755</span><span class="p">]</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">0.000907715</span>
<span class="n">W</span> <span class="o">=</span> <span class="p">[</span> <span class="mf">0.09996141</span><span class="p">]</span> <span class="n">b</span> <span class="o">=</span> <span class="p">[</span> <span class="mf">0.29989725</span><span class="p">]</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">0.000907463</span>
<span class="n">W</span> <span class="o">=</span> <span class="p">[</span> <span class="mf">0.10022032</span><span class="p">]</span> <span class="n">b</span> <span class="o">=</span> <span class="p">[</span> <span class="mf">0.29989707</span><span class="p">]</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">0.000907352</span>
<span class="n">W</span> <span class="o">=</span> <span class="p">[</span> <span class="mf">0.10039273</span><span class="p">]</span> <span class="n">b</span> <span class="o">=</span> <span class="p">[</span> <span class="mf">0.29989696</span><span class="p">]</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">0.000907302</span>
<span class="n">W</span> <span class="o">=</span> <span class="p">[</span> <span class="mf">0.10050753</span><span class="p">]</span> <span class="n">b</span> <span class="o">=</span> <span class="p">[</span> <span class="mf">0.29989687</span><span class="p">]</span> <span class="n">loss</span> <span class="o">=</span> <span class="mf">0.00090728</span>
</pre></div>
</td></tr></table>

<p>一张图展示线性回归工作原理
执行上面的代码后会在本地生成一个tmp目录，里面会产生用于tensorboard读取的数据，下面我们执行：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>tensorboard --logdir=./tmp/
</pre></div>
</td></tr></table>

<p>打开http://localhost:6006/的GRAPHS，并展开里面的一系列关键节点，如下图所示：</p>
<p>这张图就是上面这段代码生成的graph结构，这个graph描述了整个梯度下降解决线性回归问题的整个过程，每一个节点都代表了代码中的一步操作，我们来具体看一下每一部分的内容</p>
<p>详细分析线性回归的graph
首先来看我们要训练的W和b，如下图：</p>
<p>我们代码中对W共有三种操作：Assign、read、train。</p>
<p>其中assign是基于random_uniform赋值的，对应着下面这句代码：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">W</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_uniform</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;W&#39;</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<p>这里的tf.random_uniform的graph部分如下：</p>
<p>其中read对应的这句代码：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">W</span> <span class="o">*</span> <span class="n">x_data</span> <span class="o">+</span> <span class="n">b</span>
</pre></div>
</td></tr></table>

<p>其中train对应的是梯度下降训练过程的操作</p>
<p>我们代码中对b同样也有三种操作：Assign、read、train。与W不同的是它是用zeros赋初始化值的</p>
<p>我们的W和b就是通过梯度下降计算update_W和update_b，从而更新W和b的值的。这里的update_W和update_b都是基于三个输入来计算得出的：学习率learning_rate、W/b当前值、梯度gradients，过程如下图：</p>
<p>最关键的梯度下降过程由下面几个过程实现：</p>
<p>下面我们分析一下详细的计算过程，首先看这句代码：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_data</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;loss&#39;</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<p>这里的y-y_data对应着这部分：</p>
<p>那么tf.squre(y-y_data)对应着那条长长的曲线</p>
<p>下面我们看这里：</p>
<p>这里的右下角是以y-y_data为输入的，但这里的x不是我们的x_data，而是一个临时常量：2。也即是2(y-y_data)，这明显是(y-y_data)^2的导数</p>
<p>继续往上看：</p>
<p>这里是以2(y-y_data)为输入经过各种处理最终生成参数b的增量update_b，至此，我们完成了一半了，因为能够更新b了</p>
<p>我们继续往上看：</p>
<p>这里可以生成update_W用来更新W，反向追溯可以看出这个值是依赖于add_grad(也就是基于y-y_data的部分)和W以及y生成的，至此梯度下降整个过程就分析完了，</p>
<p>在这个大图中，详细计算过程如：http://stackoverflow.com/questions/39580427/how-does-tensorflow-calculate-the-gradients-for-the-tf-train-gradientdescentopti所说，一步简单的操作很普遍的被tensorflow转成了很多个节点的图，所以里面有一些细节的节点就不深入分析，因为只是一些操作的图表达，没有太重要的意义</p>
                
                  
                
              
              
                
              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../36.tensorflow-session-graph/" title="三十六-tensorflow的session和graph" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                三十六-tensorflow的session和graph
              </span>
            </div>
          </a>
        
        
          <a href="../38.make-chatbot/" title="三十八-聊天机器人构建流程" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                三十八-聊天机器人构建流程
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            版权 &copy; 2016 - 2017 shareditor.com
          </div>
        
        powered by
        <a href="http://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
        
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/application.6cdc17f0.js"></script>
      
      <script>app.initialize({version:"0.17.2",url:{base:".."}})</script>
      
    
    
      
    
  </body>
</html>