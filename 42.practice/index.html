



<!DOCTYPE html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
      
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="en">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-0.17.2, mkdocs-material-2.2.5">
    
    
      
        <title>四十二-从理论到实践开发聊天机器人1 - 自己动手做聊天机器人</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/application.bcabdff3.css">
      
        <link rel="stylesheet" href="../assets/stylesheets/application-palette.792431c1.css">
      
    
    
      <script src="../assets/javascripts/modernizr.1aa3b519.js"></script>
    
    
      
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
      <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
    
    
    
  </head>
  
    
    
    
      <body data-md-color-primary="indigo" data-md-color-accent="indigo">
    
  
    <svg class="md-svg">
      <defs>
        
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="drawer">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="search">
    <label class="md-overlay" data-md-component="overlay" for="drawer"></label>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href=".." title="自己动手做聊天机器人" class="md-header-nav__button md-logo">
          
            <i class="md-icon"></i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            
              <span class="md-header-nav__topic">
                自己动手做聊天机器人
              </span>
              <span class="md-header-nav__topic">
                四十二-从理论到实践开发聊天机器人1
              </span>
            
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          
            <label class="md-icon md-icon--search md-header-nav__button" for="search"></label>
            
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="search"></label>
  <div class="md-search__inner">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" required placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query">
      <label class="md-icon md-search__icon" for="search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset">&#xE5CD;</button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
          
        
      </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="drawer">
    <span class="md-nav__button md-logo">
      
        <i class="md-icon"></i>
      
    </span>
    自己动手做聊天机器人
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href=".." title="概述" class="md-nav__link">
      概述
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../1.knowledge/" title="一-涉及知识" class="md-nav__link">
      一-涉及知识
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../2.nltk/" title="二-初识NLTK库" class="md-nav__link">
      二-初识NLTK库
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../3.corpus/" title="三-语料与词汇资源" class="md-nav__link">
      三-语料与词汇资源
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../4.pos-tagging/" title="四-自动化词性标注" class="md-nav__link">
      四-自动化词性标注
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../5.text-classification/" title="五-文本分类" class="md-nav__link">
      五-文本分类
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../6.extract/" title="六-结构化提取" class="md-nav__link">
      六-结构化提取
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../7.grammar/" title="七-文法分析" class="md-nav__link">
      七-文法分析
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../8.nlp-review/" title="八-自然语言处理" class="md-nav__link">
      八-自然语言处理
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../9.chatbot/" title="九-聊天机器人怎么做" class="md-nav__link">
      九-聊天机器人怎么做
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../10.pos-ke/" title="十-词性标注与关键词提取" class="md-nav__link">
      十-词性标注与关键词提取
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../11.storage/" title="十一-0字节存储海量语料资源" class="md-nav__link">
      十一-0字节存储海量语料资源
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../12.semantic-dependency/" title="十二-用语言云分析依存句法和语义依存" class="md-nav__link">
      十二-用语言云分析依存句法和语义依存
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../13.linguistic-model/" title="十三-探究语言模型" class="md-nav__link">
      十三-探究语言模型
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../14.participles-art/" title="十四-探究中文分词" class="md-nav__link">
      十四-探究中文分词
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../15.probabilistic-model/" title="十五-概率图模型" class="md-nav__link">
      十五-概率图模型
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../16.bag-material/" title="十六-自然语言处理中的囊中取物" class="md-nav__link">
      十六-自然语言处理中的囊中取物
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../17.specific-mehtod/" title="十七-词性自动标注" class="md-nav__link">
      十七-词性自动标注
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../18.tree/" title="十八-生成句法分析树" class="md-nav__link">
      十八-生成句法分析树
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../19.understand/" title="十九-机器人是怎么理解“日后再说”的" class="md-nav__link">
      十九-机器人是怎么理解“日后再说”的
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../20.pos-base-method/" title="二十-语义角色标注" class="md-nav__link">
      二十-语义角色标注
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../21.tf-idf/" title="二十一-隐含语义索引模型" class="md-nav__link">
      二十一-隐含语义索引模型
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../22.artificial-neural-network/" title="二十二-人工神经网络" class="md-nav__link">
      二十二-人工神经网络
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../23.cnn/" title="二十三-用CNN做深度学习" class="md-nav__link">
      二十三-用CNN做深度学习
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../24.nlp-deep-learning/" title="二十四-将深度学习应用到NLP" class="md-nav__link">
      二十四-将深度学习应用到NLP
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../25.word2vec/" title="二十五-word2vec的实现原理" class="md-nav__link">
      二十五-word2vec的实现原理
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../26.rnn/" title="二十六-递归神经网络(RNN)" class="md-nav__link">
      二十六-递归神经网络(RNN)
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../27.auto-faq/" title="二十七-自动问答" class="md-nav__link">
      二十七-自动问答
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../28.subtitle-corpus/" title="二十八-基于美剧字幕的聊天语料库建设" class="md-nav__link">
      二十八-基于美剧字幕的聊天语料库建设
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../29.corpus-1g/" title="二十九-近1GB的三千万聊天语料" class="md-nav__link">
      二十九-近1GB的三千万聊天语料
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../30.tiny-rabbit/" title="三十-第一版聊天机器人小二兔" class="md-nav__link">
      三十-第一版聊天机器人小二兔
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../31.directive/" title="三十一-把网站流量导向小二兔" class="md-nav__link">
      三十一-把网站流量导向小二兔
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../32.word-vector/" title="三十二-用影视剧字幕语料库生成词向量" class="md-nav__link">
      三十二-用影视剧字幕语料库生成词向量
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../33.lstm-rnn/" title="三十三-LSTM-RNN—有记忆的神经网络" class="md-nav__link">
      三十三-LSTM-RNN—有记忆的神经网络
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../34.torch/" title="三十四-深度学习框架torch" class="md-nav__link">
      三十四-深度学习框架torch
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../35.lstm-learning/" title="三十五-一学会甄嬛体" class="md-nav__link">
      三十五-一学会甄嬛体
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../36.tensorflow-session-graph/" title="三十六-tensorflow的session和graph" class="md-nav__link">
      三十六-tensorflow的session和graph
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../37.tensorflow-lr/" title="三十七-tensorflow中的线性回归" class="md-nav__link">
      三十七-tensorflow中的线性回归
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../38.make-chatbot/" title="三十八-聊天机器人构建流程" class="md-nav__link">
      三十八-聊天机器人构建流程
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../39.gpu-server/" title="三十九-搭建一台GPU共享云服务" class="md-nav__link">
      三十九-搭建一台GPU共享云服务
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../40.video-knowledge-point/" title="四十-视频之开篇宣言与知识点" class="md-nav__link">
      四十-视频之开篇宣言与知识点
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../41.video-python/" title="四十一-视频之环境搭建与python基础" class="md-nav__link">
      四十一-视频之环境搭建与python基础
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="toc">
    
    
      <label class="md-nav__link md-nav__link--active" for="toc">
        四十二-从理论到实践开发聊天机器人1
      </label>
    
    <a href="./" title="四十二-从理论到实践开发聊天机器人1" class="md-nav__link md-nav__link--active">
      四十二-从理论到实践开发聊天机器人1
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
  
    <label class="md-nav__title" for="toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" title="什么是神经网络" class="md-nav__link">
    什么是神经网络
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lstm" title="什么是循环神经网络和LSTM" class="md-nav__link">
    什么是循环神经网络和LSTM
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#seq2seq" title="什么是seq2seq模型" class="md-nav__link">
    什么是seq2seq模型
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#attention" title="什么是attention模型" class="md-nav__link">
    什么是attention模型
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tensorflowseq2seq" title="用tensorflow的seq2seq制作你自己的聊天机器人" class="md-nav__link">
    用tensorflow的seq2seq制作你自己的聊天机器人
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_2" title="总结" class="md-nav__link">
    总结
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" title="参考文献" class="md-nav__link">
    参考文献
  </a>
  
</li>
      
      
      
    </ul>
  
</nav>
    
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../43.practice2/" title="四十三-从理论到实践开发聊天机器人2" class="md-nav__link">
      四十三-从理论到实践开发聊天机器人2
    </a>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
  
    <label class="md-nav__title" for="toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" title="什么是神经网络" class="md-nav__link">
    什么是神经网络
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lstm" title="什么是循环神经网络和LSTM" class="md-nav__link">
    什么是循环神经网络和LSTM
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#seq2seq" title="什么是seq2seq模型" class="md-nav__link">
    什么是seq2seq模型
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#attention" title="什么是attention模型" class="md-nav__link">
    什么是attention模型
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tensorflowseq2seq" title="用tensorflow的seq2seq制作你自己的聊天机器人" class="md-nav__link">
    用tensorflow的seq2seq制作你自己的聊天机器人
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_2" title="总结" class="md-nav__link">
    总结
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" title="参考文献" class="md-nav__link">
    参考文献
  </a>
  
</li>
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                  <h1>四十二-从理论到实践开发聊天机器人1</h1>
                
                <p>经过几个月的不断试错不断编码，终于整理出一套相对完备的理论和一套效果还不错的代码供大家把玩，训练了10个小时后效果请见文章末尾，代码已分享到github </p>
<h3 id="_1">什么是神经网络<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h3>
<p>这本小书一定要看：《Make Your Own Neural Network》，老外写的，200多页，没找到中文译本，原版百度一下可以下载到，他用非常通俗易懂的描述讲解了人工神经网络的原理并用代码实现，而且试验效果非常好，作为深度学习入门非常值得推荐。</p>
<h3 id="lstm">什么是循环神经网络和LSTM<a class="headerlink" href="#lstm" title="Permanent link">&para;</a></h3>
<p>可以参考我的这篇文章自己动手做聊天机器人 二十六-图解递归神经网络(RNN)，或者直接看Christopher Olah的<a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">2015-08-Understanding-LSTMs</a>，这篇博文被业界引用无数次了，经典中的经典。</p>
<h3 id="seq2seq">什么是seq2seq模型<a class="headerlink" href="#seq2seq" title="Permanent link">&para;</a></h3>
<p>seq2seq是基于循环神经网络的一种序列到序列模型，语言翻译、自动问答等都属于序列到序列的场景，都可以使用seq2seq模型，用seq2seq实现聊天机器人的原理可以看下<a href="http://suriyadeepan.github.io/2016-06-28-easy-seq2seq/">这篇文章</a>。tensorflow中已经有实现好的api供我们使用，但因为参数较多、原理复杂，理解起来比较晦涩，本文就让我带着大家一步一步探索并使用。</p>
<h3 id="attention">什么是attention模型<a class="headerlink" href="#attention" title="Permanent link">&para;</a></h3>
<p>attention模型(注意力模型)是为了解决seq2seq中解码器只接受编码器最后一个输出而远离了之前的输出导致的信息丢失的问题，从原理上讲，一个回答一般是基于问题中一些关键位置的信息，也就是注意力集中的地方，具体细节可以看下<a href="http://www.wildml.com/2016/01/attention-and-memory-in-deep-learning-and-nlp/">这里</a></p>
<h3 id="tensorflowseq2seq">用tensorflow的seq2seq制作你自己的聊天机器人<a class="headerlink" href="#tensorflowseq2seq" title="Permanent link">&para;</a></h3>
<p>到这里，假设你已经掌握了上面的理论部分，现在我们直接锁定在tensorflow提供给我们的强大api上。想真正利用好tensorflow必须理解好它的重要接口及其所有参数，所以第一步我们找到我们这次要使用的最<a href="https://www.tensorflow.org/api_docs/python/tf/contrib/legacy_seq2seq/embedding_attention_seq2seq">关键的接口</a>：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">embedding_attention_seq2seq</span><span class="p">(</span>
    <span class="n">encoder_inputs</span><span class="p">,</span>
    <span class="n">decoder_inputs</span><span class="p">,</span>
    <span class="n">cell</span><span class="p">,</span>
    <span class="n">num_encoder_symbols</span><span class="p">,</span>
    <span class="n">num_decoder_symbols</span><span class="p">,</span>
    <span class="n">embedding_size</span><span class="p">,</span>
    <span class="n">num_heads</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">output_projection</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="n">feed_previous</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
    <span class="n">dtype</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="n">scope</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="n">initial_state_attention</span><span class="o">=</span><span class="bp">False</span>
<span class="p">)</span>
</pre></div>
</td></tr></table>

<p>为了说明这个接口的功能，先来看一下它所涉及到的模型结构，如下所示：
<img alt="" src="../imgs/1504785200_1.png" /></p>
<p>参数encoder_inputs是一个list，list中每一项是1D的Tensor，这个Tensor的shape是[batch_size]，Tensor中每一项是一个整数，类似这样：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="p">[</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">),</span> 
<span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">),</span> 
<span class="n">array</span><span class="p">([</span><span class="mi">8</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">),</span> 
<span class="n">array</span><span class="p">([</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">),</span> 
<span class="n">array</span><span class="p">([</span><span class="mi">6</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">)]</span>
</pre></div>
</td></tr></table>

<p>其中的5个array，表示一句话的长度是5个词</p>
<p>其中每个array里有4个数，表示batch是4，也就是一共4个样本。那么可以看出第一个样本是[[0],[0],[8],[7],[6]]，第二个样本是[[0],[0],[3],[8],[2]]，这里的数字是用来区分不同词的一个id，一般通过统计得出，一个id表示一个词</p>
<p>同理，参数<strong><em>decoder_inputs</em></strong>也是和<strong><em>encoder_inputs</em></strong>一样结构，不赘述</p>
<p>参数<strong><em>cell</em></strong>是<strong><em>tf.nn.rnn_cell.RNNCell</em></strong>类型的循环神经网络单元，可以用<strong><em>tf.contrib.rnn.BasicLSTMCell</em></strong>、<strong><em>tf.contrib.rnn.GRUCell</em></strong></p>
<p>参数num_encoder_symbols是一个整数，表示encoder_inputs中的整数词id的数目，同理num_decoder_symbols表示decoder_inputs中整数词id的数目</p>
<p>embedding_size表示在内部做word embedding时转成几维向量，需要和RNNCell的size大小相等</p>
<p>num_heads表示在attention_states中的抽头数量</p>
<p>output_projection是一个(W, B)结构的tuple，W是shape为[output_size x num_decoder_symbols]的weight矩阵，B是shape为[num_decoder_symbols]的偏置向量，那么每个RNNCell的输出经过WX+B就可以映射成num_decoder_symbols维的向量，这个向量里的值表示的是任意一个decoder_symbol的可能性，也就是softmax</p>
<p>feed_previous表示decoder_inputs是我们直接提供训练数据的输入，还是用前一个RNNCell的输出映射出来的，如果feed_previous为True，那么就是用前一个RNNCell的输出，并经过WX+B映射成</p>
<p>dtype是RNN状态数据的类型，默认是tf.float32</p>
<p>scope是子图的命名，默认是“embedding_attention_seq2seq”</p>
<p>initial_state_attention表示是否初始化attentions，默认为否，表示全都初始化为0</p>
<p>它的返回值是一个(outputs, state)结构的tuple，其中outputs是一个长度为句子长度(词数，与上面encoder_inputs的list长度一样)的list，list中每一项是一个2D的tf.float32类型的Tensor，第一维度是样本数，比如4个样本则有四组Tensor，每个Tensor长度是embedding_size，像下面的样子：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>  <span class="p">[</span>
    <span class="n">array</span><span class="p">([</span>
      <span class="p">[</span><span class="o">-</span><span class="mf">0.02027004</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.017872</span>  <span class="p">,</span> <span class="o">-</span><span class="mf">0.00233014</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0437047</span> <span class="p">,</span>  <span class="mf">0.00083584</span><span class="p">,</span>
      <span class="mf">0.01339234</span><span class="p">,</span>  <span class="mf">0.02355197</span><span class="p">,</span>  <span class="mf">0.02923143</span><span class="p">],</span>
      <span class="p">[</span><span class="o">-</span><span class="mf">0.02027004</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.017872</span>  <span class="p">,</span> <span class="o">-</span><span class="mf">0.00233014</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0437047</span> <span class="p">,</span>  <span class="mf">0.00083584</span><span class="p">,</span>
      <span class="mf">0.01339234</span><span class="p">,</span>  <span class="mf">0.02355197</span><span class="p">,</span>  <span class="mf">0.02923143</span><span class="p">],</span>
      <span class="p">[</span><span class="o">-</span><span class="mf">0.02027004</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.017872</span>  <span class="p">,</span> <span class="o">-</span><span class="mf">0.00233014</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0437047</span> <span class="p">,</span>  <span class="mf">0.00083584</span><span class="p">,</span>
      <span class="mf">0.01339234</span><span class="p">,</span>  <span class="mf">0.02355197</span><span class="p">,</span>  <span class="mf">0.02923143</span><span class="p">],</span>
      <span class="p">[</span><span class="o">-</span><span class="mf">0.02027004</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.017872</span>  <span class="p">,</span> <span class="o">-</span><span class="mf">0.00233014</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0437047</span> <span class="p">,</span>  <span class="mf">0.00083584</span><span class="p">,</span>
      <span class="mf">0.01339234</span><span class="p">,</span>  <span class="mf">0.02355197</span><span class="p">,</span>  <span class="mf">0.02923143</span><span class="p">]</span>
    <span class="p">],</span><span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">),</span>
    <span class="n">array</span><span class="p">([</span>
    <span class="o">......</span>
    <span class="p">],</span><span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">),</span>  
    <span class="n">array</span><span class="p">([</span>
    <span class="o">......</span>
    <span class="p">],</span><span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">),</span>  
    <span class="n">array</span><span class="p">([</span>
    <span class="o">......</span>
    <span class="p">],</span><span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">),</span>  
    <span class="n">array</span><span class="p">([</span>
    <span class="o">......</span>
    <span class="p">],</span><span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">),</span>  
  <span class="p">]</span>
</pre></div>
</td></tr></table>

<p>其实这个outputs可以描述为5<em>4</em>8个浮点数，5是句子长度，4是样本数，8是词向量维数</p>
<p>下面再看返回的state，它是num_layers个LSTMStateTuple组成的大tuple，这里num_layers是初始化cell时的参数，表示神经网络单元有几层，一个由3层LSTM神经元组成的encoder-decoder多层循环神经网络是像下面这样的网络结构：</p>
<p><img alt="" src="../imgs/1504786934_2.png" /></p>
<p>encoder_inputs输入encoder的第一层LSTM神经元，这个神经元的output传给第二层LSTM神经元，第二层的output再传给第三层，而encoder的第一层输出的state则传给decoder第一层的LSTM神经元，依次类推，如上图所示</p>
<p>回过头来再看LSTMStateTuple这个结构，它是由两个Tensor组成的tuple，第一个tensor命名为c，由4个8维向量组成(4是batch, 8是state_size也就是词向量维度)， 第二个tensor命名为h，同样由4个8维向量组成</p>
<p>这里的c和h如下所示：</p>
<p><img alt="" src="../imgs/1504786942_3.png" /></p>
<p>c是传给下一个时序的存储数据，h是隐藏层的输出，这里的计算公式是</p>
<p>在tensorflow代码里也有对应的实现：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">concat</span> <span class="o">=</span> <span class="n">_linear</span><span class="p">([</span><span class="n">inputs</span><span class="p">,</span> <span class="n">h</span><span class="p">],</span> <span class="mi">4</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_units</span><span class="p">,</span> <span class="bp">True</span><span class="p">)</span>
<span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">o</span> <span class="o">=</span> <span class="n">array_ops</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="n">concat</span><span class="p">,</span> <span class="n">num_or_size_splits</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">new_c</span> <span class="o">=</span> <span class="p">(</span><span class="n">c</span> <span class="o">*</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">f</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forget_bias</span><span class="p">)</span> <span class="o">+</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_activation</span><span class="p">(</span><span class="n">j</span><span class="p">))</span>
<span class="n">new_h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_activation</span><span class="p">(</span><span class="n">new_c</span><span class="p">)</span> <span class="o">*</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">o</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<p>事实上，如果我们直接使用embedding_attention_seq2seq来做训练，返回的state一般是用不到的</p>
<p>下面，我们就来想办法构造这些输入参数来训练一个seq2seq模型出来</p>
<p>我们以1、3、5、7、9……奇数序列为例来构造样本，比如两个样本是[[1,3,5],[7,9,11]]和[[3,5,7],[9,11,13]]，相当于我们的：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">train_set</span> <span class="o">=</span> <span class="p">[[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">11</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">13</span><span class="p">]]]</span>
</pre></div>
</td></tr></table>

<p>为了我们能够满足不同长度的序列，需要让我们训练的序列比样本的序列长度要长一些，比如我们设置为5，即</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">input_seq_len</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">output_seq_len</span> <span class="o">=</span> <span class="mi">5</span>
</pre></div>
</td></tr></table>

<p>因为样本长度小于训练序列的长度，所以我们用0来填充，即</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">PAD_ID</span> <span class="o">=</span> <span class="mi">0</span>
</pre></div>
</td></tr></table>

<p>那么我们的第一个样本的encoder_input就是：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">encoder_input_0</span> <span class="o">=</span> <span class="p">[</span><span class="n">PAD_ID</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">input_seq_len</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]))</span> <span class="o">+</span> <span class="n">train_set</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</td></tr></table>

<p>第二个样本的encoder_input就是：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">encoder_input_1</span> <span class="o">=</span> <span class="p">[</span><span class="n">PAD_ID</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">input_seq_len</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]))</span> <span class="o">+</span> <span class="n">train_set</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</td></tr></table>

<p>decoder_input我们需要用一个GO_ID来作为起始，再输入样本序列，最后再用PAD_ID来填充，即</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">GO_ID</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">decoder_input_0</span> <span class="o">=</span> <span class="p">[</span><span class="n">GO_ID</span><span class="p">]</span> <span class="o">+</span> <span class="n">train_set</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> 
    <span class="o">+</span> <span class="p">[</span><span class="n">PAD_ID</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">output_seq_len</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">decoder_input_1</span> <span class="o">=</span> <span class="p">[</span><span class="n">GO_ID</span><span class="p">]</span> <span class="o">+</span> <span class="n">train_set</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> 
    <span class="o">+</span> <span class="p">[</span><span class="n">PAD_ID</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">output_seq_len</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<p>为了把输入转成上面讲到的embedding_attention_seq2seq输入参数encoder_inputs和decoder_inputs的格式，我们进行如下转换即可：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7
8</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">encoder_inputs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">decoder_inputs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">length_idx</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">input_seq_len</span><span class="p">):</span>
    <span class="n">encoder_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">encoder_input_0</span><span class="p">[</span><span class="n">length_idx</span><span class="p">],</span> 
                          <span class="n">encoder_input_1</span><span class="p">[</span><span class="n">length_idx</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>
<span class="k">for</span> <span class="n">length_idx</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">output_seq_len</span><span class="p">):</span>
    <span class="n">decoder_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">decoder_input_0</span><span class="p">[</span><span class="n">length_idx</span><span class="p">],</span> 
                          <span class="n">decoder_input_1</span><span class="p">[</span><span class="n">length_idx</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<p>运行已经写完的这段程序，打印出<strong><em>encoder_inputs</em></strong>和<strong><em>decoder_inputs</em></strong>如下：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="p">[</span>
  <span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">),</span> 
  <span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">),</span> 
  <span class="n">array</span><span class="p">([</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">23</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">),</span> 
  <span class="n">array</span><span class="p">([</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">25</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">),</span> 
  <span class="n">array</span><span class="p">([</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">27</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">)</span>
<span class="p">]</span>
<span class="p">[</span>
  <span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">),</span> 
  <span class="n">array</span><span class="p">([</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">29</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">),</span> 
  <span class="n">array</span><span class="p">([</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">31</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">),</span> 
  <span class="n">array</span><span class="p">([</span><span class="mi">11</span><span class="p">,</span> <span class="mi">33</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">),</span> 
  <span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">)</span>
<span class="p">]</span>
</pre></div>
</td></tr></table>

<p>好，第一步大功告成，我们把这部分独立出一个函数，整理代码如下：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># coding:utf-8</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="c1"># 输入序列长度</span>
<span class="n">input_seq_len</span> <span class="o">=</span> <span class="mi">5</span>
<span class="c1"># 输出序列长度</span>
<span class="n">output_seq_len</span> <span class="o">=</span> <span class="mi">5</span>
<span class="c1"># 空值填充0</span>
<span class="n">PAD_ID</span> <span class="o">=</span> <span class="mi">0</span>
<span class="c1"># 输出序列起始标记</span>
<span class="n">GO_ID</span> <span class="o">=</span> <span class="mi">1</span>


<span class="k">def</span> <span class="nf">get_samples</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;构造样本数据</span>

<span class="sd">    :return:</span>
<span class="sd">        encoder_inputs: [array([0, 0], dtype=int32), </span>
<span class="sd">                         array([0, 0], dtype=int32), </span>
<span class="sd">                         array([1, 3], dtype=int32),</span>
<span class="sd">                         array([3, 5], dtype=int32), </span>
<span class="sd">                         array([5, 7], dtype=int32)]</span>
<span class="sd">        decoder_inputs: [array([1, 1], dtype=int32), </span>
<span class="sd">                         array([7, 9], dtype=int32), </span>
<span class="sd">                         array([ 9, 11], dtype=int32),</span>
<span class="sd">                         array([11, 13], dtype=int32), </span>
<span class="sd">                         array([0, 0], dtype=int32)]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">train_set</span> <span class="o">=</span> <span class="p">[[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">11</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">13</span><span class="p">]]]</span>
    <span class="n">encoder_input_0</span> <span class="o">=</span> <span class="p">[</span><span class="n">PAD_ID</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">input_seq_len</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]))</span> 
                      <span class="o">+</span> <span class="n">train_set</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">encoder_input_1</span> <span class="o">=</span> <span class="p">[</span><span class="n">PAD_ID</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">input_seq_len</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]))</span> 
                      <span class="o">+</span> <span class="n">train_set</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">decoder_input_0</span> <span class="o">=</span> <span class="p">[</span><span class="n">GO_ID</span><span class="p">]</span> <span class="o">+</span> <span class="n">train_set</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> 
                      <span class="o">+</span> <span class="p">[</span><span class="n">PAD_ID</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">output_seq_len</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">decoder_input_1</span> <span class="o">=</span> <span class="p">[</span><span class="n">GO_ID</span><span class="p">]</span> <span class="o">+</span> <span class="n">train_set</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> 
                      <span class="o">+</span> <span class="p">[</span><span class="n">PAD_ID</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">output_seq_len</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">encoder_inputs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">decoder_inputs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">length_idx</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">input_seq_len</span><span class="p">):</span>
        <span class="n">encoder_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">encoder_input_0</span><span class="p">[</span><span class="n">length_idx</span><span class="p">],</span> 
                              <span class="n">encoder_input_1</span><span class="p">[</span><span class="n">length_idx</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">length_idx</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">output_seq_len</span><span class="p">):</span>
        <span class="n">decoder_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">decoder_input_0</span><span class="p">[</span><span class="n">length_idx</span><span class="p">],</span> 
                              <span class="n">decoder_input_1</span><span class="p">[</span><span class="n">length_idx</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">encoder_inputs</span><span class="p">,</span> <span class="n">decoder_inputs</span>
</pre></div>
</td></tr></table>

<p>搞定上面这部分之后，我们开始构造模型，我们了解了tensorflow的运行过程是先构造图，再塞数据计算的，所以我们构建模型的过程实际上就是构建一张图，</p>
<p>首先我们创建<strong><em>encoder_inputs</em></strong>和<strong><em>decoder_inputs的placeholder</em></strong>(占位符)：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7
8
9</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="n">encoder_inputs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">decoder_inputs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">input_seq_len</span><span class="p">):</span>
    <span class="n">encoder_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">],</span> 
                          <span class="n">name</span><span class="o">=</span><span class="s2">&quot;encoder{0}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">output_seq_len</span><span class="p">):</span>
    <span class="n">decoder_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">],</span> 
                          <span class="n">name</span><span class="o">=</span><span class="s2">&quot;decoder{0}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)))</span>
</pre></div>
</td></tr></table>

<p>接下来我们创建一个记忆单元数目为size=8的LSTM神经元结构：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">size</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">BasicLSTMCell</span><span class="p">(</span><span class="n">size</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<p>我们假设我们要训练的奇数序列最大数值是输入最大10输出最大16，那么</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">num_encoder_symbols</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">num_decoder_symbols</span> <span class="o">=</span> <span class="mi">16</span>
</pre></div>
</td></tr></table>

<p>然后把参数传入<strong><em>embedding_attention_seq2seq</em></strong>获取<strong><em>output</em></strong></p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.contrib.legacy_seq2seq.python.ops</span> <span class="kn">import</span> <span class="n">seq2seq</span>
<span class="n">outputs</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">seq2seq</span><span class="o">.</span><span class="n">embedding_attention_seq2seq</span><span class="p">(</span>
                    <span class="n">encoder_inputs</span><span class="p">,</span>
                    <span class="n">decoder_inputs</span><span class="p">[:</span><span class="n">output_seq_len</span><span class="p">],</span>
                    <span class="n">cell</span><span class="p">,</span>
                    <span class="n">cell</span><span class="p">,</span>
                    <span class="n">num_encoder_symbols</span><span class="o">=</span><span class="n">num_encoder_symbols</span><span class="p">,</span>
                    <span class="n">num_decoder_symbols</span><span class="o">=</span><span class="n">num_decoder_symbols</span><span class="p">,</span>
                    <span class="n">embedding_size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span>
                    <span class="n">output_projection</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                    <span class="n">feed_previous</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<p>为了说明之后的操作，我们先把这部分运行一下，看看输出的output是个什么样的数据，我们先把上面的构建模型部分放到一个单独的函数里，如下：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">get_model</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;构造模型</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">encoder_inputs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">decoder_inputs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">input_seq_len</span><span class="p">):</span>
        <span class="n">encoder_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">],</span> 
                          <span class="n">name</span><span class="o">=</span><span class="s2">&quot;encoder{0}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">output_seq_len</span><span class="p">):</span>
        <span class="n">decoder_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">],</span> 
                          <span class="n">name</span><span class="o">=</span><span class="s2">&quot;decoder{0}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)))</span>

    <span class="n">cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">BasicLSTMCell</span><span class="p">(</span><span class="n">size</span><span class="p">)</span>

    <span class="c1"># 这里输出的状态我们不需要</span>
    <span class="n">outputs</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">seq2seq</span><span class="o">.</span><span class="n">embedding_attention_seq2seq</span><span class="p">(</span>
                        <span class="n">encoder_inputs</span><span class="p">,</span>
                        <span class="n">decoder_inputs</span><span class="p">,</span>
                        <span class="n">cell</span><span class="p">,</span>
                        <span class="n">num_encoder_symbols</span><span class="o">=</span><span class="n">num_encoder_symbols</span><span class="p">,</span>
                        <span class="n">num_decoder_symbols</span><span class="o">=</span><span class="n">num_decoder_symbols</span><span class="p">,</span>
                        <span class="n">embedding_size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span>
                        <span class="n">output_projection</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                        <span class="n">feed_previous</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                        <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">encoder_inputs</span><span class="p">,</span> <span class="n">decoder_inputs</span><span class="p">,</span> <span class="n">outputs</span>
</pre></div>
</td></tr></table>

<p>来构造运行时的<strong><em>session</em></strong>，并填入样本数据：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">sample_encoder_inputs</span><span class="p">,</span> <span class="n">sample_decoder_inputs</span> <span class="o">=</span> <span class="n">get_samples</span><span class="p">()</span>
    <span class="n">encoder_inputs</span><span class="p">,</span> <span class="n">decoder_inputs</span><span class="p">,</span> <span class="n">outputs</span> <span class="o">=</span> <span class="n">get_model</span><span class="p">()</span>
    <span class="n">input_feed</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">input_seq_len</span><span class="p">):</span>
        <span class="n">input_feed</span><span class="p">[</span><span class="n">encoder_inputs</span><span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">sample_encoder_inputs</span><span class="p">[</span><span class="n">l</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">output_seq_len</span><span class="p">):</span>
        <span class="n">input_feed</span><span class="p">[</span><span class="n">decoder_inputs</span><span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">sample_decoder_inputs</span><span class="p">[</span><span class="n">l</span><span class="p">]</span>

    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">input_feed</span><span class="p">)</span>
    <span class="k">print</span> <span class="n">outputs</span>
</pre></div>
</td></tr></table>

<p>我们看到这里输出的outputs是由5个array组成的list(5是序列长度)，每个array由两个size是16的list组成(2表示2个样本，16表示输出符号有16个)</p>
<p>这里的outputs实际上应该对应seq2seq的输出，也就是下图中的W、X、Y、Z、EOS，也就是decoder_inputs[1:]，也就是我们样本里的[7,9,11]和[9,11,13]</p>
<p><img alt="" src="../imgs/1504786979_5.png" /></p>
<p>但是我们的<strong><em>decoder_inputs</em></strong>的结构是这样的：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="p">[</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">),</span> <span class="n">array</span><span class="p">([</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">29</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">),</span> <span class="n">array</span><span class="p">([</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">31</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">),</span> <span class="n">array</span><span class="p">([</span><span class="mi">11</span><span class="p">,</span> <span class="mi">33</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">),</span> <span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">)]</span>
</pre></div>
</td></tr></table>

<p>与这里的outputs稍有不同，所以不是直接的对应关系，那么到底是什么关系呢？我们先来看一个<a href="https://www.tensorflow.org/api_docs/python/tf/contrib/legacy_seq2seq/sequence_loss">损失函数的说明</a>：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7
8
9</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">sequence_loss</span><span class="p">(</span>
    <span class="n">logits</span><span class="p">,</span>
    <span class="n">targets</span><span class="p">,</span>
    <span class="n">weights</span><span class="p">,</span>
    <span class="n">average_across_timesteps</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">average_across_batch</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">softmax_loss_function</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="bp">None</span>
<span class="p">)</span>
</pre></div>
</td></tr></table>

<p>这个函数的原理可以看这个公式(损失函数，目标词语的平均负对数概率最小)：</p>
<p>其中logits是一个由多个2D的shape为[batch * num_decoder_symbols]的Tensor组成的list，我们这里batch就是2，num_decoder_symbols就是16，这里组成list的Tensor的个数是output_seq_len，所以我们刚才得到的outputs刚好符合</p>
<p>其中targets是一个和logits一样长度(output_seq_len)的list，list里每一项是一个整数组成的1D的Tensor，每个Tensor的shape是[batch]，数据类型是tf.int32，这刚好和我们的decoder_inputs[1:]也就是刚才说的W、X、Y、Z、EOS结构一样</p>
<p>其中weights是一个和targets结构一样，只是数据类型是tf.float32</p>
<p>所以这个函数就是用来计算加权交叉熵损失的，这里面的weights我们需要初始化他的占位符，如下：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">target_weights</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">target_weights</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">],</span> 
                          <span class="n">name</span><span class="o">=</span><span class="s2">&quot;weight{0}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)))</span>
</pre></div>
</td></tr></table>

<p>那么我们计算得出的损失值就是：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">targets</span> <span class="o">=</span> <span class="p">[</span><span class="n">decoder_inputs</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">decoder_inputs</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)]</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">seq2seq</span><span class="o">.</span><span class="n">sequence_loss</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">target_weights</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<p>看到这里，其实我们遇到一个问题，这里的targets长度比decoder_inputs少了一个，为了让长度保持一致，需要我们对前面decoder_inputs的初始化做个调整，把长度加1</p>
<p>那么问题来了，这里我们多了一个target_weights这个placeholder，那么我们用什么数据来填充这个占位符呢？因为我们要计算的是加权交叉熵损失，也就是对于有意义的数权重大，无意义的权重小，所以我们把targets中有值的赋值为1，没值的赋值为0，所有代码整理后如下：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>  1
  2
  3
  4
  5
  6
  7
  8
  9
 10
 11
 12
 13
 14
 15
 16
 17
 18
 19
 20
 21
 22
 23
 24
 25
 26
 27
 28
 29
 30
 31
 32
 33
 34
 35
 36
 37
 38
 39
 40
 41
 42
 43
 44
 45
 46
 47
 48
 49
 50
 51
 52
 53
 54
 55
 56
 57
 58
 59
 60
 61
 62
 63
 64
 65
 66
 67
 68
 69
 70
 71
 72
 73
 74
 75
 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># coding:utf-8</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.contrib.legacy_seq2seq.python.ops</span> <span class="kn">import</span> <span class="n">seq2seq</span>

<span class="c1"># 输入序列长度</span>
<span class="n">input_seq_len</span> <span class="o">=</span> <span class="mi">5</span>
<span class="c1"># 输出序列长度</span>
<span class="n">output_seq_len</span> <span class="o">=</span> <span class="mi">5</span>
<span class="c1"># 空值填充0</span>
<span class="n">PAD_ID</span> <span class="o">=</span> <span class="mi">0</span>
<span class="c1"># 输出序列起始标记</span>
<span class="n">GO_ID</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># LSTM神经元size</span>
<span class="n">size</span> <span class="o">=</span> <span class="mi">8</span>
<span class="c1"># 最大输入符号数</span>
<span class="n">num_encoder_symbols</span> <span class="o">=</span> <span class="mi">10</span>
<span class="c1"># 最大输出符号数</span>
<span class="n">num_decoder_symbols</span> <span class="o">=</span> <span class="mi">16</span>


<span class="k">def</span> <span class="nf">get_samples</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;构造样本数据</span>

<span class="sd">    :return:</span>
<span class="sd">        encoder_inputs: [array([0, 0], dtype=int32), </span>
<span class="sd">                         array([0, 0], dtype=int32), </span>
<span class="sd">                         array([1, 3], dtype=int32),</span>
<span class="sd">                         array([3, 5], dtype=int32), </span>
<span class="sd">                         array([5, 7], dtype=int32)]</span>
<span class="sd">        decoder_inputs: [array([1, 1], dtype=int32), </span>
<span class="sd">                         array([7, 9], dtype=int32), </span>
<span class="sd">                         array([ 9, 11], dtype=int32),</span>
<span class="sd">                         array([11, 13], dtype=int32), </span>
<span class="sd">                         array([0, 0], dtype=int32)]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">train_set</span> <span class="o">=</span> <span class="p">[[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">11</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">13</span><span class="p">]]]</span>
    <span class="n">encoder_input_0</span> <span class="o">=</span> <span class="p">[</span><span class="n">PAD_ID</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">input_seq_len</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]))</span> 
                         <span class="o">+</span> <span class="n">train_set</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">encoder_input_1</span> <span class="o">=</span> <span class="p">[</span><span class="n">PAD_ID</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">input_seq_len</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]))</span> 
                         <span class="o">+</span> <span class="n">train_set</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">decoder_input_0</span> <span class="o">=</span> <span class="p">[</span><span class="n">GO_ID</span><span class="p">]</span> <span class="o">+</span> <span class="n">train_set</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> 
                         <span class="o">+</span> <span class="p">[</span><span class="n">PAD_ID</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">output_seq_len</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">decoder_input_1</span> <span class="o">=</span> <span class="p">[</span><span class="n">GO_ID</span><span class="p">]</span> <span class="o">+</span> <span class="n">train_set</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> 
                         <span class="o">+</span> <span class="p">[</span><span class="n">PAD_ID</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">output_seq_len</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">encoder_inputs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">decoder_inputs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">target_weights</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">length_idx</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">input_seq_len</span><span class="p">):</span>
        <span class="n">encoder_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">encoder_input_0</span><span class="p">[</span><span class="n">length_idx</span><span class="p">],</span> 
                         <span class="n">encoder_input_1</span><span class="p">[</span><span class="n">length_idx</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">length_idx</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">output_seq_len</span><span class="p">):</span>
        <span class="n">decoder_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">decoder_input_0</span><span class="p">[</span><span class="n">length_idx</span><span class="p">],</span> 
                         <span class="n">decoder_input_1</span><span class="p">[</span><span class="n">length_idx</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>
        <span class="n">target_weights</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
            <span class="mf">0.0</span> <span class="k">if</span> <span class="n">length_idx</span> <span class="o">==</span> <span class="n">output_seq_len</span> <span class="o">-</span> <span class="mi">1</span> 
                         <span class="ow">or</span> <span class="n">decoder_input_0</span><span class="p">[</span><span class="n">length_idx</span><span class="p">]</span> <span class="o">==</span> <span class="n">PAD_ID</span> <span class="k">else</span> <span class="mf">1.0</span><span class="p">,</span>
            <span class="mf">0.0</span> <span class="k">if</span> <span class="n">length_idx</span> <span class="o">==</span> <span class="n">output_seq_len</span> <span class="o">-</span> <span class="mi">1</span> 
                         <span class="ow">or</span> <span class="n">decoder_input_1</span><span class="p">[</span><span class="n">length_idx</span><span class="p">]</span> <span class="o">==</span> <span class="n">PAD_ID</span> <span class="k">else</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">encoder_inputs</span><span class="p">,</span> <span class="n">decoder_inputs</span><span class="p">,</span> <span class="n">target_weights</span>


<span class="k">def</span> <span class="nf">get_model</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;构造模型</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">encoder_inputs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">decoder_inputs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">target_weights</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">input_seq_len</span><span class="p">):</span>
        <span class="n">encoder_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">],</span> 
                          <span class="n">name</span><span class="o">=</span><span class="s2">&quot;encoder{0}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">output_seq_len</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">decoder_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">],</span> 
                          <span class="n">name</span><span class="o">=</span><span class="s2">&quot;decoder{0}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">output_seq_len</span><span class="p">):</span>
        <span class="n">target_weights</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">],</span>
                          <span class="n">name</span><span class="o">=</span><span class="s2">&quot;weight{0}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)))</span>

    <span class="c1"># decoder_inputs左移一个时序作为targets</span>
    <span class="n">targets</span> <span class="o">=</span> <span class="p">[</span><span class="n">decoder_inputs</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">output_seq_len</span><span class="p">)]</span>

    <span class="n">cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">BasicLSTMCell</span><span class="p">(</span><span class="n">size</span><span class="p">)</span>

    <span class="c1"># 这里输出的状态我们不需要</span>
    <span class="n">outputs</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">seq2seq</span><span class="o">.</span><span class="n">embedding_attention_seq2seq</span><span class="p">(</span>
                        <span class="n">encoder_inputs</span><span class="p">,</span>
                        <span class="n">decoder_inputs</span><span class="p">[:</span><span class="n">output_seq_len</span><span class="p">],</span>
                        <span class="n">cell</span><span class="p">,</span>
                        <span class="n">num_encoder_symbols</span><span class="o">=</span><span class="n">num_encoder_symbols</span><span class="p">,</span>
                        <span class="n">num_decoder_symbols</span><span class="o">=</span><span class="n">num_decoder_symbols</span><span class="p">,</span>
                        <span class="n">embedding_size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span>
                        <span class="n">output_projection</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                        <span class="n">feed_previous</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                        <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="c1"># 计算加权交叉熵损失</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">seq2seq</span><span class="o">.</span><span class="n">sequence_loss</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">target_weights</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">encoder_inputs</span><span class="p">,</span> <span class="n">decoder_inputs</span><span class="p">,</span> <span class="n">target_weights</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">loss</span>


<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
        <span class="n">sample_encoder_inputs</span><span class="p">,</span> <span class="n">sample_decoder_inputs</span><span class="p">,</span> <span class="n">sample_target_weights</span> 
                          <span class="o">=</span> <span class="n">get_samples</span><span class="p">()</span>
        <span class="n">encoder_inputs</span><span class="p">,</span> <span class="n">decoder_inputs</span><span class="p">,</span> <span class="n">target_weights</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">get_model</span><span class="p">()</span>

        <span class="n">input_feed</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">input_seq_len</span><span class="p">):</span>
            <span class="n">input_feed</span><span class="p">[</span><span class="n">encoder_inputs</span><span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">sample_encoder_inputs</span><span class="p">[</span><span class="n">l</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">output_seq_len</span><span class="p">):</span>
            <span class="n">input_feed</span><span class="p">[</span><span class="n">decoder_inputs</span><span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">sample_decoder_inputs</span><span class="p">[</span><span class="n">l</span><span class="p">]</span>
            <span class="n">input_feed</span><span class="p">[</span><span class="n">target_weights</span><span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">sample_target_weights</span><span class="p">[</span><span class="n">l</span><span class="p">]</span>
        <span class="n">input_feed</span><span class="p">[</span><span class="n">decoder_inputs</span><span class="p">[</span><span class="n">output_seq_len</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

        <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">input_feed</span><span class="p">)</span>
        <span class="k">print</span> <span class="n">loss</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</td></tr></table>

<p>我们可以运行以上代码来输出最终loss值</p>
<p>到这里远远没有结束，我们的旅程才刚刚开始，下面是怎么训练这个模型，首先我们需要经过多轮计算让这里的loss变得很小，这就需要运用梯度下降来更新参数，我们先来看一下tensorflow提供给我们的<a href="https://www.tensorflow.org/api_docs/python/tf/train/GradientDescentOptimizer">梯度下降的类</a>：</p>
<p>Class GradientDescentOptimizer的构造方法如下：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="fm">__init__</span><span class="p">(</span>
    <span class="n">learning_rate</span><span class="p">,</span>
    <span class="n">use_locking</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;GradientDescent&#39;</span>
<span class="p">)</span>
</pre></div>
</td></tr></table>

<p>其中关键就是第一个参数：学习率</p>
<p>他的另外一个方法是计算梯度：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7
8</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">compute_gradients</span><span class="p">(</span>
    <span class="n">loss</span><span class="p">,</span>
    <span class="n">var_list</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="n">gate_gradients</span><span class="o">=</span><span class="n">GATE_OP</span>
    <span class="n">aggregation_method</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="n">colocate_gradients_with_ops</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
    <span class="n">grad_loss</span><span class="o">=</span><span class="bp">None</span>
<span class="p">)</span>
</pre></div>
</td></tr></table>

<p>其中关键参数loss就是传入的误差值，他的返回值是(gradient, variable)组成的list</p>
<p>再看另外一个方法是更新参数：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">apply_gradients</span><span class="p">(</span>
    <span class="n">grads_and_vars</span><span class="p">,</span>
    <span class="n">global_step</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="bp">None</span>
<span class="p">)</span>
</pre></div>
</td></tr></table>

<p>其中grads_and_vars就是compute_gradients的返回值</p>
<p>那么根据loss计算梯度并更新参数的方法如下：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">GradientDescentOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">)</span>
<span class="n">update</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="n">opt</span><span class="o">.</span><span class="n">compute_gradients</span><span class="p">(</span><span class="n">loss</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<p>所以，我们队main函数增加个循环迭代，如下：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
        <span class="n">sample_encoder_inputs</span><span class="p">,</span> <span class="n">sample_decoder_inputs</span><span class="p">,</span> <span class="n">sample_target_weights</span> 
                          <span class="o">=</span> <span class="n">get_samples</span><span class="p">()</span>
        <span class="n">encoder_inputs</span><span class="p">,</span> <span class="n">decoder_inputs</span><span class="p">,</span> <span class="n">target_weights</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">update</span> 
                          <span class="o">=</span> <span class="n">get_model</span><span class="p">()</span>

        <span class="n">input_feed</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">input_seq_len</span><span class="p">):</span>
            <span class="n">input_feed</span><span class="p">[</span><span class="n">encoder_inputs</span><span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">sample_encoder_inputs</span><span class="p">[</span><span class="n">l</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">output_seq_len</span><span class="p">):</span>
            <span class="n">input_feed</span><span class="p">[</span><span class="n">decoder_inputs</span><span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">sample_decoder_inputs</span><span class="p">[</span><span class="n">l</span><span class="p">]</span>
            <span class="n">input_feed</span><span class="p">[</span><span class="n">target_weights</span><span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">sample_target_weights</span><span class="p">[</span><span class="n">l</span><span class="p">]</span>
        <span class="n">input_feed</span><span class="p">[</span><span class="n">decoder_inputs</span><span class="p">[</span><span class="n">output_seq_len</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

        <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>
        <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
            <span class="p">[</span><span class="n">loss_ret</span><span class="p">,</span> <span class="n">_</span><span class="p">]</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">loss</span><span class="p">,</span> <span class="n">update</span><span class="p">],</span> <span class="n">input_feed</span><span class="p">)</span>
            <span class="k">print</span> <span class="n">loss_ret</span>
</pre></div>
</td></tr></table>

<p>运行代码后我们看到loss_ret唰唰的收敛，如下：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="mf">2.82825</span>
<span class="mf">2.51962</span>
<span class="mf">2.22479</span>
<span class="mf">1.92842</span>
<span class="mf">1.62379</span>
<span class="mf">1.31437</span>
<span class="mf">1.01518</span>
<span class="mf">0.749776</span>
<span class="err">……</span>
<span class="mf">0.00601374</span>
<span class="mf">0.00590649</span>
<span class="mf">0.00580256</span>
<span class="mf">0.00570199</span>
<span class="mf">0.00560467</span>
<span class="mf">0.00551019</span>
<span class="mf">0.00541872</span>
<span class="err">……</span>
</pre></div>
</td></tr></table>

<p>看来我们的训练逻辑可以跑通了，接下来就是实现预测的逻辑了，就是我们只输入样本的encoder_input，看能不能自动预测出decoder_input</p>
<p>首先，我们要能够把训练好的模型保存起来，以便重新启动做预测时能够加载：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">get_model</span><span class="p">():</span>
      <span class="o">...</span>
<span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables</span><span class="p">())</span>
      <span class="k">return</span> <span class="o">...</span><span class="p">,</span> <span class="n">saver</span>
</pre></div>
</td></tr></table>

<p>在训练结束后执行</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="s1">&#39;./model/demo&#39;</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<p>这样模型会存储到./model目录下以demo开头的一些文件中，之后我们要加载时就先调用：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">saver</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="s1">&#39;./model/demo&#39;</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<p>其次，因为我们在做预测的时候，原则上不能有decoder_inputs输入了，所以在执行时的decoder_inputs就要取前一个时序的输出，这时候embedding_attention_seq2seq的feed_previous参数有派上用场了，这个参数的含义就是：若为True则decoder里每一步输入都用前一步的输出来填充，如下图：</p>
<p><img alt="" src="../imgs/1504787039_7.png" /></p>
<p>所以，我们的get_model需要传递参数来区分训练时和预测是不同的feed_previous配置，另外，考虑到预测时main函数也是不同的，索性我们分开两个函数来分别做train和predict，整理好的一份完整代码如下（为了更好理解，完整代码和上面稍有出入，请以这份代码为准）：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>  1
  2
  3
  4
  5
  6
  7
  8
  9
 10
 11
 12
 13
 14
 15
 16
 17
 18
 19
 20
 21
 22
 23
 24
 25
 26
 27
 28
 29
 30
 31
 32
 33
 34
 35
 36
 37
 38
 39
 40
 41
 42
 43
 44
 45
 46
 47
 48
 49
 50
 51
 52
 53
 54
 55
 56
 57
 58
 59
 60
 61
 62
 63
 64
 65
 66
 67
 68
 69
 70
 71
 72
 73
 74
 75
 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># coding:utf-8</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.contrib.legacy_seq2seq.python.ops</span> <span class="kn">import</span> <span class="n">seq2seq</span>

<span class="c1"># 输入序列长度</span>
<span class="n">input_seq_len</span> <span class="o">=</span> <span class="mi">5</span>
<span class="c1"># 输出序列长度</span>
<span class="n">output_seq_len</span> <span class="o">=</span> <span class="mi">5</span>
<span class="c1"># 空值填充0</span>
<span class="n">PAD_ID</span> <span class="o">=</span> <span class="mi">0</span>
<span class="c1"># 输出序列起始标记</span>
<span class="n">GO_ID</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># 结尾标记</span>
<span class="n">EOS_ID</span> <span class="o">=</span> <span class="mi">2</span>
<span class="c1"># LSTM神经元size</span>
<span class="n">size</span> <span class="o">=</span> <span class="mi">8</span>
<span class="c1"># 最大输入符号数</span>
<span class="n">num_encoder_symbols</span> <span class="o">=</span> <span class="mi">10</span>
<span class="c1"># 最大输出符号数</span>
<span class="n">num_decoder_symbols</span> <span class="o">=</span> <span class="mi">16</span>
<span class="c1"># 学习率</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span>


<span class="k">def</span> <span class="nf">get_samples</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;构造样本数据</span>

<span class="sd">    :return:</span>
<span class="sd">        encoder_inputs: [array([0, 0], dtype=int32), </span>
<span class="sd">                         array([0, 0], dtype=int32), </span>
<span class="sd">                         array([5, 5], dtype=int32),</span>
<span class="sd">                         array([7, 7], dtype=int32), </span>
<span class="sd">                         array([9, 9], dtype=int32)]</span>
<span class="sd">        decoder_inputs: [array([1, 1], dtype=int32), </span>
<span class="sd">                         array([11, 11], dtype=int32), </span>
<span class="sd">                         array([13, 13], dtype=int32),</span>
<span class="sd">                         array([15, 15], dtype=int32), </span>
<span class="sd">                         array([2, 2], dtype=int32)]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">train_set</span> <span class="o">=</span> <span class="p">[[[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span> <span class="p">[</span><span class="mi">11</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="n">EOS_ID</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">11</span><span class="p">],</span> <span class="p">[</span><span class="mi">13</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="n">EOS_ID</span><span class="p">]]]</span>
    <span class="n">raw_encoder_input</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">raw_decoder_input</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">train_set</span><span class="p">:</span>
        <span class="n">raw_encoder_input</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">PAD_ID</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">input_seq_len</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span> <span class="o">+</span> <span class="n">sample</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">raw_decoder_input</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">GO_ID</span><span class="p">]</span> <span class="o">+</span> <span class="n">sample</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> 
                         <span class="o">+</span> <span class="p">[</span><span class="n">PAD_ID</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">output_seq_len</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>

    <span class="n">encoder_inputs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">decoder_inputs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">target_weights</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">length_idx</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">input_seq_len</span><span class="p">):</span>
        <span class="n">encoder_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">encoder_input</span><span class="p">[</span><span class="n">length_idx</span><span class="p">]</span> 
                          <span class="k">for</span> <span class="n">encoder_input</span> <span class="ow">in</span> <span class="n">raw_encoder_input</span><span class="p">],</span> 
                                                  <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">length_idx</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">output_seq_len</span><span class="p">):</span>
        <span class="n">decoder_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">decoder_input</span><span class="p">[</span><span class="n">length_idx</span><span class="p">]</span> 
                          <span class="k">for</span> <span class="n">decoder_input</span> <span class="ow">in</span> <span class="n">raw_decoder_input</span><span class="p">],</span> 
                                                  <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span>
        <span class="n">target_weights</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
            <span class="mf">0.0</span> <span class="k">if</span> <span class="n">length_idx</span> <span class="o">==</span> <span class="n">output_seq_len</span> <span class="o">-</span> <span class="mi">1</span> 
                         <span class="ow">or</span> <span class="n">decoder_input</span><span class="p">[</span><span class="n">length_idx</span><span class="p">]</span> <span class="o">==</span> <span class="n">PAD_ID</span> <span class="k">else</span> <span class="mf">1.0</span> 
                         <span class="k">for</span> <span class="n">decoder_input</span> <span class="ow">in</span> <span class="n">raw_decoder_input</span>
        <span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">encoder_inputs</span><span class="p">,</span> <span class="n">decoder_inputs</span><span class="p">,</span> <span class="n">target_weights</span>


<span class="k">def</span> <span class="nf">get_model</span><span class="p">(</span><span class="n">feed_previous</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;构造模型</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">encoder_inputs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">decoder_inputs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">target_weights</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">input_seq_len</span><span class="p">):</span>
        <span class="n">encoder_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">],</span> 
                          <span class="n">name</span><span class="o">=</span><span class="s2">&quot;encoder{0}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">output_seq_len</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">decoder_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">],</span> 
                          <span class="n">name</span><span class="o">=</span><span class="s2">&quot;decoder{0}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">output_seq_len</span><span class="p">):</span>
        <span class="n">target_weights</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">],</span> 
                         <span class="n">name</span><span class="o">=</span><span class="s2">&quot;weight{0}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)))</span>

    <span class="c1"># decoder_inputs左移一个时序作为targets</span>
    <span class="n">targets</span> <span class="o">=</span> <span class="p">[</span><span class="n">decoder_inputs</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">output_seq_len</span><span class="p">)]</span>

    <span class="n">cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">BasicLSTMCell</span><span class="p">(</span><span class="n">size</span><span class="p">)</span>

    <span class="c1"># 这里输出的状态我们不需要</span>
    <span class="n">outputs</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">seq2seq</span><span class="o">.</span><span class="n">embedding_attention_seq2seq</span><span class="p">(</span>
                        <span class="n">encoder_inputs</span><span class="p">,</span>
                        <span class="n">decoder_inputs</span><span class="p">[:</span><span class="n">output_seq_len</span><span class="p">],</span>
                        <span class="n">cell</span><span class="p">,</span>
                        <span class="n">num_encoder_symbols</span><span class="o">=</span><span class="n">num_encoder_symbols</span><span class="p">,</span>
                        <span class="n">num_decoder_symbols</span><span class="o">=</span><span class="n">num_decoder_symbols</span><span class="p">,</span>
                        <span class="n">embedding_size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span>
                        <span class="n">output_projection</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                        <span class="n">feed_previous</span><span class="o">=</span><span class="n">feed_previous</span><span class="p">,</span>
                        <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="c1"># 计算加权交叉熵损失</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">seq2seq</span><span class="o">.</span><span class="n">sequence_loss</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">target_weights</span><span class="p">)</span>
    <span class="c1"># 梯度下降优化器</span>
    <span class="n">opt</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">GradientDescentOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">)</span>
    <span class="c1"># 优化目标：让loss最小化</span>
    <span class="n">update</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="n">opt</span><span class="o">.</span><span class="n">compute_gradients</span><span class="p">(</span><span class="n">loss</span><span class="p">))</span>
    <span class="c1"># 模型持久化</span>
    <span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">encoder_inputs</span><span class="p">,</span> <span class="n">decoder_inputs</span><span class="p">,</span> <span class="n">target_weights</span><span class="p">,</span> 
                          <span class="n">outputs</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">update</span><span class="p">,</span> <span class="n">saver</span><span class="p">,</span> <span class="n">targets</span>


<span class="k">def</span> <span class="nf">train</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    训练过程</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
        <span class="n">sample_encoder_inputs</span><span class="p">,</span> <span class="n">sample_decoder_inputs</span><span class="p">,</span> <span class="n">sample_target_weights</span> 
                          <span class="o">=</span> <span class="n">get_samples</span><span class="p">()</span>
        <span class="n">encoder_inputs</span><span class="p">,</span> <span class="n">decoder_inputs</span><span class="p">,</span> <span class="n">target_weights</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">update</span><span class="p">,</span> <span class="n">saver</span><span class="p">,</span> <span class="n">targets</span> 
                          <span class="o">=</span> <span class="n">get_model</span><span class="p">()</span>

        <span class="n">input_feed</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">input_seq_len</span><span class="p">):</span>
            <span class="n">input_feed</span><span class="p">[</span><span class="n">encoder_inputs</span><span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">sample_encoder_inputs</span><span class="p">[</span><span class="n">l</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">output_seq_len</span><span class="p">):</span>
            <span class="n">input_feed</span><span class="p">[</span><span class="n">decoder_inputs</span><span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">sample_decoder_inputs</span><span class="p">[</span><span class="n">l</span><span class="p">]</span>
            <span class="n">input_feed</span><span class="p">[</span><span class="n">target_weights</span><span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">sample_target_weights</span><span class="p">[</span><span class="n">l</span><span class="p">]</span>
        <span class="n">input_feed</span><span class="p">[</span><span class="n">decoder_inputs</span><span class="p">[</span><span class="n">output_seq_len</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

        <span class="c1"># 全部变量初始化</span>
        <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>

        <span class="c1"># 训练200次迭代，每隔10次打印一次loss</span>
        <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="mi">200</span><span class="p">):</span>
            <span class="p">[</span><span class="n">loss_ret</span><span class="p">,</span> <span class="n">_</span><span class="p">]</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">loss</span><span class="p">,</span> <span class="n">update</span><span class="p">],</span> <span class="n">input_feed</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">print</span> <span class="s1">&#39;step=&#39;</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="s1">&#39;loss=&#39;</span><span class="p">,</span> <span class="n">loss_ret</span>

        <span class="c1"># 模型持久化</span>
        <span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="s1">&#39;./model/demo&#39;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">predict</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    预测过程</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
        <span class="n">sample_encoder_inputs</span><span class="p">,</span> <span class="n">sample_decoder_inputs</span><span class="p">,</span> <span class="n">sample_target_weights</span> 
                          <span class="o">=</span> <span class="n">get_samples</span><span class="p">()</span>
        <span class="n">encoder_inputs</span><span class="p">,</span> <span class="n">decoder_inputs</span><span class="p">,</span> <span class="n">target_weights</span><span class="p">,</span> 
                          <span class="n">outputs</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">update</span><span class="p">,</span> <span class="n">saver</span><span class="p">,</span> <span class="n">targets</span> 
                          <span class="o">=</span> <span class="n">get_model</span><span class="p">(</span><span class="n">feed_previous</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="c1"># 从文件恢复模型</span>
        <span class="n">saver</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="s1">&#39;./model/demo&#39;</span><span class="p">)</span>

        <span class="n">input_feed</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">input_seq_len</span><span class="p">):</span>
            <span class="n">input_feed</span><span class="p">[</span><span class="n">encoder_inputs</span><span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">sample_encoder_inputs</span><span class="p">[</span><span class="n">l</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">output_seq_len</span><span class="p">):</span>
            <span class="n">input_feed</span><span class="p">[</span><span class="n">decoder_inputs</span><span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">sample_decoder_inputs</span><span class="p">[</span><span class="n">l</span><span class="p">]</span>
            <span class="n">input_feed</span><span class="p">[</span><span class="n">target_weights</span><span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">sample_target_weights</span><span class="p">[</span><span class="n">l</span><span class="p">]</span>
        <span class="n">input_feed</span><span class="p">[</span><span class="n">decoder_inputs</span><span class="p">[</span><span class="n">output_seq_len</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

        <span class="c1"># 预测输出</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">input_feed</span><span class="p">)</span>
        <span class="c1"># 一共试验样本有2个，所以分别遍历</span>
        <span class="k">for</span> <span class="n">sample_index</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
            <span class="c1"># 因为输出数据每一个是num_decoder_symbols维的</span>
            <span class="c1"># 因此找到数值最大的那个就是预测的id，就是这里的argmax函数的功能</span>
            <span class="n">outputs_seq</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logit</span><span class="p">[</span><span class="n">sample_index</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span> <span class="k">for</span> <span class="n">logit</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">]</span>
            <span class="c1"># 如果是结尾符，那么后面的语句就不输出了</span>
            <span class="k">if</span> <span class="n">EOS_ID</span> <span class="ow">in</span> <span class="n">outputs_seq</span><span class="p">:</span>
                <span class="n">outputs_seq</span> <span class="o">=</span> <span class="n">outputs_seq</span><span class="p">[:</span><span class="n">outputs_seq</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">EOS_ID</span><span class="p">)]</span>
            <span class="n">outputs_seq</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">outputs_seq</span><span class="p">]</span>
            <span class="k">print</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">outputs_seq</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;train&#39;</span><span class="p">:</span>
        <span class="n">train</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">predict</span><span class="p">()</span>
</pre></div>
</td></tr></table>

<p>比如文件命名为demo.py，那么首先执行./demo.py train训练好模型，然后执行./demo.py predict，输出为：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="m">11</span> <span class="m">13</span> <span class="m">15</span>
<span class="m">11</span> <span class="m">13</span> <span class="m">15</span>
</pre></div>
</td></tr></table>

<p>至此，我们算有了小小的成就了，那就是我们根据输入的样本(两个[5, 7, 9])预测出了输出的11 13 15了</p>
<p>比较仔细的人会发现，在做预测的时候依然是按照完整的encoder_inputs和decoder_inputs计算的，那么怎么能证明模型不是直接使用了decoder_inputs来预测出的输出呢？那么我们来继续改进predict，让我们可以手工输入一串数字(只有encoder部分)，看看模型能不能预测出输出</p>
<p>首先我们实现一个从输入空格分隔的数字id串，转成预测用的encoder、decoder、target_weight的函数</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">seq_to_encoder</span><span class="p">(</span><span class="n">input_seq</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;从输入空格分隔的数字id串，转成预测用的encoder、decoder、target_weight等</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">input_seq_array</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">input_seq</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span>
    <span class="n">encoder_input</span> <span class="o">=</span> <span class="p">[</span><span class="n">PAD_ID</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">input_seq_len</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_seq_array</span><span class="p">))</span> <span class="o">+</span> <span class="n">input_seq_array</span>
    <span class="n">decoder_input</span> <span class="o">=</span> <span class="p">[</span><span class="n">GO_ID</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">PAD_ID</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">output_seq_len</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">encoder_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">v</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">encoder_input</span><span class="p">]</span>
    <span class="n">decoder_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">v</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">decoder_input</span><span class="p">]</span>
    <span class="n">target_weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)]</span> <span class="o">*</span> <span class="n">output_seq_len</span>
    <span class="k">return</span> <span class="n">encoder_inputs</span><span class="p">,</span> <span class="n">decoder_inputs</span><span class="p">,</span> <span class="n">target_weights</span>
</pre></div>
</td></tr></table>

<p>然后我们改写predict函数如下：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">predict</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    预测过程</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
        <span class="n">encoder_inputs</span><span class="p">,</span> <span class="n">decoder_inputs</span><span class="p">,</span> <span class="n">target_weights</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">update</span><span class="p">,</span> <span class="n">saver</span> 
                          <span class="o">=</span> <span class="n">get_model</span><span class="p">(</span><span class="n">feed_previous</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">saver</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="s1">&#39;./model/demo&#39;</span><span class="p">)</span>
        <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;&gt; &quot;</span><span class="p">)</span>
        <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>
        <span class="n">input_seq</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">stdin</span><span class="o">.</span><span class="n">readline</span><span class="p">()</span>
        <span class="k">while</span> <span class="n">input_seq</span><span class="p">:</span>
            <span class="n">input_seq</span> <span class="o">=</span> <span class="n">input_seq</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="n">sample_encoder_inputs</span><span class="p">,</span> <span class="n">sample_decoder_inputs</span><span class="p">,</span> <span class="n">sample_target_weights</span> 
                          <span class="o">=</span> <span class="n">seq_to_encoder</span><span class="p">(</span><span class="n">input_seq</span><span class="p">)</span>

            <span class="n">input_feed</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">input_seq_len</span><span class="p">):</span>
                <span class="n">input_feed</span><span class="p">[</span><span class="n">encoder_inputs</span><span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">sample_encoder_inputs</span><span class="p">[</span><span class="n">l</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">output_seq_len</span><span class="p">):</span>
                <span class="n">input_feed</span><span class="p">[</span><span class="n">decoder_inputs</span><span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">sample_decoder_inputs</span><span class="p">[</span><span class="n">l</span><span class="p">]</span>
                <span class="n">input_feed</span><span class="p">[</span><span class="n">target_weights</span><span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">sample_target_weights</span><span class="p">[</span><span class="n">l</span><span class="p">]</span>
            <span class="n">input_feed</span><span class="p">[</span><span class="n">decoder_inputs</span><span class="p">[</span><span class="n">output_seq_len</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

            <span class="c1"># 预测输出</span>
            <span class="n">outputs_seq</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">input_feed</span><span class="p">)</span>
            <span class="c1"># 因为输出数据每一个是num_decoder_symbols维的</span>
            <span class="c1"># 因此找到数值最大的那个就是预测的id，就是这里的argmax函数的功能</span>
            <span class="n">outputs_seq</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logit</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span> <span class="k">for</span> <span class="n">logit</span> <span class="ow">in</span> <span class="n">outputs_seq</span><span class="p">]</span>
            <span class="c1"># 如果是结尾符，那么后面的语句就不输出了</span>
            <span class="k">if</span> <span class="n">EOS_ID</span> <span class="ow">in</span> <span class="n">outputs_seq</span><span class="p">:</span>
                <span class="n">outputs_seq</span> <span class="o">=</span> <span class="n">outputs_seq</span><span class="p">[:</span><span class="n">outputs_seq</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">EOS_ID</span><span class="p">)]</span>
            <span class="n">outputs_seq</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">outputs_seq</span><span class="p">]</span>
            <span class="k">print</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">outputs_seq</span><span class="p">)</span>

            <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;&gt; &quot;</span><span class="p">)</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>
            <span class="n">input_seq</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">stdin</span><span class="o">.</span><span class="n">readline</span><span class="p">()</span>
</pre></div>
</td></tr></table>

<p>好，重新执行./demo.py predict如下：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="o">[</span>root@localhost $<span class="o">]</span> python demo.py predict
&gt; <span class="m">5</span> <span class="m">7</span> <span class="m">9</span>
<span class="m">11</span> <span class="m">13</span> <span class="m">15</span>
&gt;
</pre></div>
</td></tr></table>

<p>我们实际上只训练了两个完全一样的样本：[5, 7, 9], [11, 13, 15, EOS_ID]，那么我们如果输入一个新的测试样本会怎么样呢？他能不能预测出我们是在推导奇数序列呢？</p>
<p>当我们输入7 9 11的时候发现他报错了，原因是我们设置了num_encoder_symbols = 10，而11无法表达了，所以我们为了训练一个强大的模型，我们修改参数并增加样本，如下：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># 最大输入符号数</span>
<span class="n">num_encoder_symbols</span> <span class="o">=</span> <span class="mi">32</span>
<span class="c1"># 最大输出符号数</span>
<span class="n">num_decoder_symbols</span> <span class="o">=</span> <span class="mi">32</span>
<span class="err">……</span>
<span class="n">train_set</span> <span class="o">=</span> <span class="p">[</span>
              <span class="p">[[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span> <span class="p">[</span><span class="mi">11</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="n">EOS_ID</span><span class="p">]],</span> 
              <span class="p">[[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">11</span><span class="p">],</span> <span class="p">[</span><span class="mi">13</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="n">EOS_ID</span><span class="p">]],</span> 
              <span class="p">[[</span><span class="mi">15</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mi">19</span><span class="p">],</span> <span class="p">[</span><span class="mi">21</span><span class="p">,</span> <span class="mi">23</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="n">EOS_ID</span><span class="p">]]</span>
            <span class="p">]</span>
<span class="err">……</span>
</pre></div>
</td></tr></table>

<p>我们把迭代次数扩大到10000次</p>
<p>训练好后重新预测结果如下：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>&gt; <span class="m">5</span> <span class="m">7</span> <span class="m">9</span>
<span class="m">11</span> <span class="m">13</span> <span class="m">15</span>
&gt; <span class="m">11</span> <span class="m">13</span> <span class="m">15</span>
<span class="m">13</span> <span class="m">17</span>
&gt; <span class="m">7</span> <span class="m">9</span> <span class="m">11</span>
<span class="m">13</span> <span class="m">15</span> <span class="m">17</span>
&gt; <span class="m">15</span> <span class="m">17</span> <span class="m">19</span>
<span class="m">21</span> <span class="m">23</span> <span class="m">25</span>
&gt; <span class="m">6</span> <span class="m">8</span> <span class="m">10</span>
<span class="m">11</span> <span class="m">13</span> <span class="m">15</span>
&gt;
</pre></div>
</td></tr></table>

<p>我们发现，对于输入的样本，预测效果还是非常好的，但是如果换成其他的输入，就还是在样本的输出里找某一个最相近的结果作为预测结果，并不会思考，没有智能，所以这个模型更适合做分类，不适合做推理</p>
<p>但是现在，我们依然在玩的只是数字的游戏，怎么样才能和中文对话扯上关系呢？很简单，在训练时把中文词汇转成id号，在预测时，把预测到的id转成中文就可以了</p>
<p>下面我们新建一个word_token.py文件，并建一个WordToken类，其中load函数负责加载样本，并生成word2id_dict和id2word_dict词典，word2id函数负责将词汇转成id，id2word负责将id转成词汇：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># coding:utf-8</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">jieba</span>


<span class="k">class</span> <span class="nc">WordToken</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># 最小起始id号, 保留的用于表示特殊标记</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">START_ID</span> <span class="o">=</span> <span class="mi">4</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">word2id_dict</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">id2word_dict</span> <span class="o">=</span> <span class="p">{}</span>


    <span class="k">def</span> <span class="nf">load_file_list</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">file_list</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        加载样本文件列表，全部切词后统计词频，按词频由高到低排序后顺次编号</span>
<span class="sd">        并存到self.word2id_dict和self.id2word_dict中</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">words_count</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="nb">file</span> <span class="ow">in</span> <span class="n">file_list</span><span class="p">:</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="nb">file</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file_object</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">file_object</span><span class="o">.</span><span class="n">readlines</span><span class="p">():</span>
                    <span class="n">line</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
                    <span class="n">seg_list</span> <span class="o">=</span> <span class="n">jieba</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
                    <span class="k">for</span> <span class="nb">str</span> <span class="ow">in</span> <span class="n">seg_list</span><span class="p">:</span>
                        <span class="k">if</span> <span class="nb">str</span> <span class="ow">in</span> <span class="n">words_count</span><span class="p">:</span>
                            <span class="n">words_count</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">words_count</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">words_count</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="n">sorted_list</span> <span class="o">=</span> <span class="p">[[</span><span class="n">v</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">words_count</span><span class="o">.</span><span class="n">items</span><span class="p">()]</span>
        <span class="n">sorted_list</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sorted_list</span><span class="p">):</span>
            <span class="n">word</span> <span class="o">=</span> <span class="n">item</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">word2id_dict</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">START_ID</span> <span class="o">+</span> <span class="n">index</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">id2word_dict</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">START_ID</span> <span class="o">+</span> <span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="n">word</span>


    <span class="k">def</span> <span class="nf">word2id</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">word</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="nb">unicode</span><span class="p">):</span>
            <span class="k">print</span> <span class="s2">&quot;Exception: error word not unicode&quot;</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">word</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">word2id_dict</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">word2id_dict</span><span class="p">[</span><span class="n">word</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">None</span>


    <span class="k">def</span> <span class="nf">id2word</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">id</span><span class="p">):</span>
        <span class="nb">id</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">id</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">id</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">id2word_dict</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">id2word_dict</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">None</span>
</pre></div>
</td></tr></table>

<p>下面在demo.py中修改我们的get_train_set如下：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">get_train_set</span><span class="p">():</span>
    <span class="k">global</span> <span class="n">num_encoder_symbols</span><span class="p">,</span> <span class="n">num_decoder_symbols</span>
    <span class="n">train_set</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;./samples/question&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">question_file</span><span class="p">:</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;./samples/answer&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">answer_file</span><span class="p">:</span>
            <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
                <span class="n">question</span> <span class="o">=</span> <span class="n">question_file</span><span class="o">.</span><span class="n">readline</span><span class="p">()</span>
                <span class="n">answer</span> <span class="o">=</span> <span class="n">answer_file</span><span class="o">.</span><span class="n">readline</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">question</span> <span class="ow">and</span> <span class="n">answer</span><span class="p">:</span>
                    <span class="n">question</span> <span class="o">=</span> <span class="n">question</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
                    <span class="n">answer</span> <span class="o">=</span> <span class="n">answer</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>

                    <span class="n">question_id_list</span> <span class="o">=</span> <span class="n">get_id_list_from</span><span class="p">(</span><span class="n">question</span><span class="p">)</span>
                    <span class="n">answer_id_list</span> <span class="o">=</span> <span class="n">get_id_list_from</span><span class="p">(</span><span class="n">answer</span><span class="p">)</span>
                    <span class="n">answer_id_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">EOS_ID</span><span class="p">)</span>
                    <span class="n">train_set</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">question_id_list</span><span class="p">,</span> <span class="n">answer_id_list</span><span class="p">])</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">break</span>
    <span class="k">return</span> <span class="n">train_set</span>
</pre></div>
</td></tr></table>

<p>其中这里的get_id_list_from实现为：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7
8</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">get_id_list_from</span><span class="p">(</span><span class="n">sentence</span><span class="p">):</span>
    <span class="n">sentence_id_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">seg_list</span> <span class="o">=</span> <span class="n">jieba</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>
    <span class="k">for</span> <span class="nb">str</span> <span class="ow">in</span> <span class="n">seg_list</span><span class="p">:</span>
        <span class="nb">id</span> <span class="o">=</span> <span class="n">wordToken</span><span class="o">.</span><span class="n">word2id</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">id</span><span class="p">:</span>
            <span class="n">sentence_id_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">wordToken</span><span class="o">.</span><span class="n">word2id</span><span class="p">(</span><span class="nb">str</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">sentence_id_list</span>
</pre></div>
</td></tr></table>

<p>而这里的wordToken来自于：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7
8</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">word_token</span>
<span class="kn">import</span> <span class="nn">jieba</span>
<span class="n">wordToken</span> <span class="o">=</span> <span class="n">word_token</span><span class="o">.</span><span class="n">WordToken</span><span class="p">()</span>

<span class="c1"># 放在全局的位置，为了动态算出num_encoder_symbols和num_decoder_symbols</span>
<span class="n">max_token_id</span> <span class="o">=</span> <span class="n">wordToken</span><span class="o">.</span><span class="n">load_file_list</span><span class="p">([</span><span class="s1">&#39;./samples/question&#39;</span><span class="p">,</span> <span class="s1">&#39;./samples/answer&#39;</span><span class="p">])</span>
<span class="n">num_encoder_symbols</span> <span class="o">=</span> <span class="n">max_token_id</span> <span class="o">+</span> <span class="mi">5</span>
<span class="n">num_decoder_symbols</span> <span class="o">=</span> <span class="n">max_token_id</span> <span class="o">+</span> <span class="mi">5</span>
</pre></div>
</td></tr></table>

<p>然后我们把训练代码改成：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7
8</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>        <span class="c1"># 训练很多次迭代，每隔10次打印一次loss，可以看情况直接ctrl+c停止</span>
        <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="mi">100000</span><span class="p">):</span>
            <span class="p">[</span><span class="n">loss_ret</span><span class="p">,</span> <span class="n">_</span><span class="p">]</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">loss</span><span class="p">,</span> <span class="n">update</span><span class="p">],</span> <span class="n">input_feed</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">print</span> <span class="s1">&#39;step=&#39;</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="s1">&#39;loss=&#39;</span><span class="p">,</span> <span class="n">loss_ret</span>

                <span class="c1"># 模型持久化</span>
                <span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="s1">&#39;./model/demo&#39;</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<p>预测的代码我们也需要做相应的修改：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">predict</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    预测过程</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
        <span class="n">encoder_inputs</span><span class="p">,</span> <span class="n">decoder_inputs</span><span class="p">,</span> <span class="n">target_weights</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">update</span><span class="p">,</span> <span class="n">saver</span> 
                        <span class="o">=</span> <span class="n">get_model</span><span class="p">(</span><span class="n">feed_previous</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">saver</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="s1">&#39;./model/demo&#39;</span><span class="p">)</span>
        <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;&gt; &quot;</span><span class="p">)</span>
        <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>
        <span class="n">input_seq</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">stdin</span><span class="o">.</span><span class="n">readline</span><span class="p">()</span>
        <span class="k">while</span> <span class="n">input_seq</span><span class="p">:</span>
            <span class="n">input_seq</span> <span class="o">=</span> <span class="n">input_seq</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="n">input_id_list</span> <span class="o">=</span> <span class="n">get_id_list_from</span><span class="p">(</span><span class="n">input_seq</span><span class="p">)</span>
            <span class="k">if</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">input_id_list</span><span class="p">)):</span>
                <span class="n">sample_encoder_inputs</span><span class="p">,</span> <span class="n">sample_decoder_inputs</span><span class="p">,</span> <span class="n">sample_target_weights</span> 
                        <span class="o">=</span> <span class="n">seq_to_encoder</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">input_id_list</span><span class="p">]))</span>

                <span class="n">input_feed</span> <span class="o">=</span> <span class="p">{}</span>
                <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">input_seq_len</span><span class="p">):</span>
                    <span class="n">input_feed</span><span class="p">[</span><span class="n">encoder_inputs</span><span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">sample_encoder_inputs</span><span class="p">[</span><span class="n">l</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">output_seq_len</span><span class="p">):</span>
                    <span class="n">input_feed</span><span class="p">[</span><span class="n">decoder_inputs</span><span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">sample_decoder_inputs</span><span class="p">[</span><span class="n">l</span><span class="p">]</span>
                    <span class="n">input_feed</span><span class="p">[</span><span class="n">target_weights</span><span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">sample_target_weights</span><span class="p">[</span><span class="n">l</span><span class="p">]</span>
                <span class="n">input_feed</span><span class="p">[</span><span class="n">decoder_inputs</span><span class="p">[</span><span class="n">output_seq_len</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> 
                        <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

                <span class="c1"># 预测输出</span>
                <span class="n">outputs_seq</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">input_feed</span><span class="p">)</span>
                <span class="c1"># 因为输出数据每一个是num_decoder_symbols维的</span>
                <span class="c1"># 因此找到数值最大的那个就是预测的id，就是这里的argmax函数的功能</span>
                <span class="n">outputs_seq</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logit</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span> <span class="k">for</span> <span class="n">logit</span> <span class="ow">in</span> <span class="n">outputs_seq</span><span class="p">]</span>
                <span class="c1"># 如果是结尾符，那么后面的语句就不输出了</span>
                <span class="k">if</span> <span class="n">EOS_ID</span> <span class="ow">in</span> <span class="n">outputs_seq</span><span class="p">:</span>
                    <span class="n">outputs_seq</span> <span class="o">=</span> <span class="n">outputs_seq</span><span class="p">[:</span><span class="n">outputs_seq</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">EOS_ID</span><span class="p">)]</span>
                <span class="n">outputs_seq</span> <span class="o">=</span> <span class="p">[</span><span class="n">wordToken</span><span class="o">.</span><span class="n">id2word</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">outputs_seq</span><span class="p">]</span>
                <span class="k">print</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">outputs_seq</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">print</span> <span class="s2">&quot;WARN：词汇不在服务区&quot;</span>

            <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;&gt; &quot;</span><span class="p">)</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>
            <span class="n">input_seq</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">stdin</span><span class="o">.</span><span class="n">readline</span><span class="p">()</span>
</pre></div>
</td></tr></table>

<p>下面我们尝试用存储在['./samples/question', './samples/answer']中的1000个对话样本来训练，使得loss输出收敛到一定程度(比如1.0)以下：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>python demo.py train
</pre></div>
</td></tr></table>

<p>到1.0以下后可以手工ctrl+c停止，因为我们每隔10个step都会store一次模型</p>
<p>训练情况如下：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="o">[</span>root@localhost $<span class="o">]</span> python demo.py train
Building prefix dict from the default dictionary ...
Loading model from cache /var/folders/tq/c0kp5y857x138x5vf8bzxfc80000gp/T/jieba.cache
Loading model cost <span class="m">0</span>.442 seconds.
Prefix dict has been built succesfully.
<span class="nv">step</span><span class="o">=</span> <span class="m">0</span> <span class="nv">loss</span><span class="o">=</span> <span class="m">7</span>.57641
<span class="nv">step</span><span class="o">=</span> <span class="m">10</span> <span class="nv">loss</span><span class="o">=</span> <span class="m">7</span>.51317
<span class="nv">step</span><span class="o">=</span> <span class="m">20</span> <span class="nv">loss</span><span class="o">=</span> <span class="m">7</span>.4462
<span class="nv">step</span><span class="o">=</span> <span class="m">30</span> <span class="nv">loss</span><span class="o">=</span> <span class="m">7</span>.37086
<span class="nv">step</span><span class="o">=</span> <span class="m">40</span> <span class="nv">loss</span><span class="o">=</span> <span class="m">7</span>.28131
<span class="nv">step</span><span class="o">=</span> <span class="m">50</span> <span class="nv">loss</span><span class="o">=</span> <span class="m">7</span>.1697
<span class="nv">step</span><span class="o">=</span> <span class="m">60</span> <span class="nv">loss</span><span class="o">=</span> <span class="m">7</span>.02524
<span class="nv">step</span><span class="o">=</span> <span class="m">70</span> <span class="nv">loss</span><span class="o">=</span> <span class="m">6</span>.83556
<span class="nv">step</span><span class="o">=</span> <span class="m">80</span> <span class="nv">loss</span><span class="o">=</span> <span class="m">6</span>.60554
<span class="nv">step</span><span class="o">=</span> <span class="m">90</span> <span class="nv">loss</span><span class="o">=</span> <span class="m">6</span>.41139
</pre></div>
</td></tr></table>

<p>我们发现模型收敛的非常慢，因为我们设置的学习率是0.1，我们希望首先学习率大一些，每当下一步的loss和上一步相比反弹(反而增大)的时候我们再尝试降低学习率，方法如下，首先我们不再直接用learning_rate，而是初始化一个学习率：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>init_learning_rate = 1
</pre></div>
</td></tr></table>

<p>然后在get_model中创建一个变量，并用init_learning_rate初始化：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>learning_rate = tf.Variable(float(init_learning_rate), trainable=False, dtype=tf.float32)
</pre></div>
</td></tr></table>

<p>之后再创建一个操作，目的是再适当的时候把学习率打9折：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>learning_rate_decay_op = learning_rate.assign(learning_rate * 0.9)
</pre></div>
</td></tr></table>

<p>之后在训练代码中这样调整：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>        <span class="c1"># 训练很多次迭代，每隔10次打印一次loss，可以看情况直接ctrl+c停止</span>
        <span class="n">previous_losses</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="mi">100000</span><span class="p">):</span>
            <span class="p">[</span><span class="n">loss_ret</span><span class="p">,</span> <span class="n">_</span><span class="p">]</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">loss</span><span class="p">,</span> <span class="n">update</span><span class="p">],</span> <span class="n">input_feed</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">print</span> <span class="s1">&#39;step=&#39;</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="s1">&#39;loss=&#39;</span><span class="p">,</span> 
                        <span class="n">loss_ret</span><span class="p">,</span> <span class="s1">&#39;learning_rate=&#39;</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

                <span class="k">if</span> <span class="n">loss_ret</span> <span class="o">&gt;</span> <span class="nb">max</span><span class="p">(</span><span class="n">previous_losses</span><span class="p">[</span><span class="o">-</span><span class="mi">5</span><span class="p">:]):</span>
                    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">learning_rate_decay_op</span><span class="p">)</span>
                <span class="n">previous_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_ret</span><span class="p">)</span>

                <span class="c1"># 模型持久化</span>
                <span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="s1">&#39;./model/demo&#39;</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<p>这样在训练时可以实现快速收敛：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="o">[</span>root@localhost $<span class="o">]</span> python demo.py train
Building prefix dict from the default dictionary ...
Loading model from cache /var/folders/tq/c0kp5y857x138x5vf8bzxfc80000gp/T/jieba.cache
Loading model cost <span class="m">0</span>.465 seconds.
Prefix dict has been built succesfully.
<span class="nv">step</span><span class="o">=</span> <span class="m">0</span> <span class="nv">loss</span><span class="o">=</span> <span class="m">7</span>.5769 <span class="nv">learning_rate</span><span class="o">=</span> <span class="m">1</span>.0
<span class="nv">step</span><span class="o">=</span> <span class="m">10</span> <span class="nv">loss</span><span class="o">=</span> <span class="m">6</span>.32053 <span class="nv">learning_rate</span><span class="o">=</span> <span class="m">1</span>.0
<span class="nv">step</span><span class="o">=</span> <span class="m">20</span> <span class="nv">loss</span><span class="o">=</span> <span class="m">5</span>.73492 <span class="nv">learning_rate</span><span class="o">=</span> <span class="m">1</span>.0
<span class="nv">step</span><span class="o">=</span> <span class="m">30</span> <span class="nv">loss</span><span class="o">=</span> <span class="m">5</span>.59705 <span class="nv">learning_rate</span><span class="o">=</span> <span class="m">1</span>.0
<span class="nv">step</span><span class="o">=</span> <span class="m">40</span> <span class="nv">loss</span><span class="o">=</span> <span class="m">5</span>.5177 <span class="nv">learning_rate</span><span class="o">=</span> <span class="m">1</span>.0
<span class="nv">step</span><span class="o">=</span> <span class="m">50</span> <span class="nv">loss</span><span class="o">=</span> <span class="m">5</span>.47604 <span class="nv">learning_rate</span><span class="o">=</span> <span class="m">1</span>.0
<span class="nv">step</span><span class="o">=</span> <span class="m">60</span> <span class="nv">loss</span><span class="o">=</span> <span class="m">5</span>.39912 <span class="nv">learning_rate</span><span class="o">=</span> <span class="m">1</span>.0
<span class="nv">step</span><span class="o">=</span> <span class="m">70</span> <span class="nv">loss</span><span class="o">=</span> <span class="m">5</span>.29099 <span class="nv">learning_rate</span><span class="o">=</span> <span class="m">1</span>.0
<span class="nv">step</span><span class="o">=</span> <span class="m">80</span> <span class="nv">loss</span><span class="o">=</span> <span class="m">5</span>.60937 <span class="nv">learning_rate</span><span class="o">=</span> <span class="m">1</span>.0
<span class="nv">step</span><span class="o">=</span> <span class="m">90</span> <span class="nv">loss</span><span class="o">=</span> <span class="m">5</span>.10457 <span class="nv">learning_rate</span><span class="o">=</span> <span class="m">0</span>.9
<span class="nv">step</span><span class="o">=</span> <span class="m">100</span> <span class="nv">loss</span><span class="o">=</span> <span class="m">5</span>.07913 <span class="nv">learning_rate</span><span class="o">=</span> <span class="m">0</span>.9
<span class="nv">step</span><span class="o">=</span> <span class="m">110</span> <span class="nv">loss</span><span class="o">=</span> <span class="m">5</span>.03715 <span class="nv">learning_rate</span><span class="o">=</span> <span class="m">0</span>.9
<span class="nv">step</span><span class="o">=</span> <span class="m">120</span> <span class="nv">loss</span><span class="o">=</span> <span class="m">5</span>.14339 <span class="nv">learning_rate</span><span class="o">=</span> <span class="m">0</span>.9
<span class="nv">step</span><span class="o">=</span> <span class="m">130</span> <span class="nv">loss</span><span class="o">=</span> <span class="m">5</span>.29311 <span class="nv">learning_rate</span><span class="o">=</span> <span class="m">0</span>.9
<span class="nv">step</span><span class="o">=</span> <span class="m">140</span> <span class="nv">loss</span><span class="o">=</span> <span class="m">5</span>.04177 <span class="nv">learning_rate</span><span class="o">=</span> <span class="m">0</span>.9
<span class="nv">step</span><span class="o">=</span> <span class="m">150</span> <span class="nv">loss</span><span class="o">=</span> <span class="m">4</span>.98884 <span class="nv">learning_rate</span><span class="o">=</span> <span class="m">0</span>.9
</pre></div>
</td></tr></table>

<p>在我的mac机器历时10个小时，终于修成正果，一共1000条样本，共进行了20700次迭代，最终loss收敛到1.11342：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>step= 20700 loss= 1.11342 learning_rate= 0.0471012
</pre></div>
</td></tr></table>

<p>预测效果如下：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="o">[</span>root@localhost $<span class="o">]</span> python demo.py predict
Building prefix dict from the default dictionary ...
Loading model from cache /var/folders/tq/c0kp5y857x138x5vf8bzxfc80000gp/T/jieba.cache
Loading model cost <span class="m">0</span>.969 seconds.
Prefix dict has been built succesfully.
&gt; 你好
你 也好 ~
&gt; 呵呵
傻 逼 呵呵
&gt; 哈哈
笑 屁
&gt; 你是谁
我 是 小猴子
&gt; 早
WARN：词汇不在服务区
&gt; 早上好
哈哈
&gt; 屁
你 屁 会
&gt; 滚蛋
WARN：词汇不在服务区
&gt; 傻逼
他妈 逼 的
</pre></div>
</td></tr></table>

<p>看起来效果还是有点靠谱的，最终版代码分享在<a href="https://github.com/warmheartli/ChatBotCourse/tree/master/chatbotv5">这里</a></p>
<h3 id="_2">总结<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h3>
<p>本文从理论到实践讲解了怎么一步一步实现一个自动聊天机器人模型，并基于1000条样本，用了10个小时训练了一个聊天模型，试验效果比较好，核心逻辑是调用了tensorflow的embedding_attention_seq2seq，也就是带注意力的seq2seq模型，其中神经网络单元是LSTM。</p>
<p>由于语料有限，设备有限，只验证了小规模样本，如果你希望训练一个强大的聊天机器人可以自己来搞到高质量的对话语料，也欢迎试用我整理的3千万影视剧字幕语料库，获取方式：《自己动手做聊天机器人 二十九-重磅：近1GB的三千万聊天语料供出》。</p>
<p>更欢迎聊天机器人爱好者加入我们的“自己动手做聊天机器人微信交流群”，加群方式：加我微信(warmheartli)并说明“加聊天机器人群”即可。</p>
<h3 id="_3">参考文献<a class="headerlink" href="#_3" title="Permanent link">&para;</a></h3>
<p><a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">http://colah.github.io/posts/2015-08-Understanding-LSTMs/</a></p>
<p><a href="http://suriyadeepan.github.io/2016-06-28-easy-seq2seq/">http://suriyadeepan.github.io/2016-06-28-easy-seq2seq/</a></p>
<p><a href="http://www.wildml.com/2016/01/attention-and-memory-in-deep-learning-and-nlp/">http://www.wildml.com/2016/01/attention-and-memory-in-deep-learning-and-nlp/</a></p>
<p><a href="https://arxiv.org/abs/1406.1078">https://arxiv.org/abs/1406.1078</a></p>
<p><a href="https://arxiv.org/abs/1409.3215">https://arxiv.org/abs/1409.3215</a></p>
<p><a href="https://arxiv.org/abs/1409.0473">https://arxiv.org/abs/1409.0473</a></p>
                
                  
                
              
              
                
              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../41.video-python/" title="四十一-视频之环境搭建与python基础" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                四十一-视频之环境搭建与python基础
              </span>
            </div>
          </a>
        
        
          <a href="../43.practice2/" title="四十三-从理论到实践开发聊天机器人2" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                四十三-从理论到实践开发聊天机器人2
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            版权 &copy; 2016 - 2017 shareditor.com
          </div>
        
        powered by
        <a href="http://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
        
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/application.6cdc17f0.js"></script>
      
      <script>app.initialize({version:"0.17.2",url:{base:".."}})</script>
      
    
    
      
    
  </body>
</html>