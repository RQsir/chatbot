



<!DOCTYPE html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
      
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="en">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-0.17.2, mkdocs-material-2.2.1">
    
    
      
        <title>三十八-聊天机器人构建流程 - 自己动手做聊天机器人</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/application.41c6761c.css">
      
        <link rel="stylesheet" href="../assets/stylesheets/application-palette.792431c1.css">
      
    
    
      <script src="../assets/javascripts/modernizr.1aa3b519.js"></script>
    
    
      
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
      <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
    
    
    
  </head>
  
    
    
    
      <body data-md-color-primary="indigo" data-md-color-accent="indigo">
    
  
    <svg class="md-svg">
      <defs>
        
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="drawer">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="search">
    <label class="md-overlay" data-md-component="overlay" for="drawer"></label>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href=".." title="自己动手做聊天机器人" class="md-header-nav__button md-logo">
          
            <i class="md-icon"></i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            
              <span class="md-header-nav__topic">
                自己动手做聊天机器人
              </span>
              <span class="md-header-nav__topic">
                三十八-聊天机器人构建流程
              </span>
            
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          
            <label class="md-icon md-icon--search md-header-nav__button" for="search"></label>
            
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="search"></label>
  <div class="md-search__inner">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" required placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query">
      <label class="md-icon md-search__icon" for="search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset">&#xE5CD;</button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
          
        
      </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="drawer">
    <span class="md-nav__button md-logo">
      
        <i class="md-icon"></i>
      
    </span>
    自己动手做聊天机器人
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href=".." title="概述" class="md-nav__link">
      概述
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../1.knowledge/" title="一-涉及知识" class="md-nav__link">
      一-涉及知识
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../2.nltk/" title="二-初识NLTK库" class="md-nav__link">
      二-初识NLTK库
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../3.corpus/" title="三-语料与词汇资源" class="md-nav__link">
      三-语料与词汇资源
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../4.pos-tagging/" title="四-自动化词性标注" class="md-nav__link">
      四-自动化词性标注
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../5.text-classification/" title="五-文本分类" class="md-nav__link">
      五-文本分类
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../6.extract/" title="六-结构化提取" class="md-nav__link">
      六-结构化提取
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../7.grammar/" title="七-文法分析" class="md-nav__link">
      七-文法分析
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../8.nlp-review/" title="八-自然语言处理" class="md-nav__link">
      八-自然语言处理
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../9.chatbot/" title="九-聊天机器人怎么做" class="md-nav__link">
      九-聊天机器人怎么做
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../10.pos-ke/" title="十-词性标注与关键词提取" class="md-nav__link">
      十-词性标注与关键词提取
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../11.storage/" title="十一-0字节存储海量语料资源" class="md-nav__link">
      十一-0字节存储海量语料资源
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../12.semantic-dependency/" title="十二-用语言云分析依存句法和语义依存" class="md-nav__link">
      十二-用语言云分析依存句法和语义依存
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../13.linguistic-model/" title="十三-探究语言模型" class="md-nav__link">
      十三-探究语言模型
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../14.participles-art/" title="十四-探究中文分词" class="md-nav__link">
      十四-探究中文分词
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../15.probabilistic-model/" title="十五-概率图模型" class="md-nav__link">
      十五-概率图模型
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../16.bag-material/" title="十六-自然语言处理中的囊中取物" class="md-nav__link">
      十六-自然语言处理中的囊中取物
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../17.specific-mehtod/" title="十七-词性自动标注" class="md-nav__link">
      十七-词性自动标注
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../18.tree/" title="十八-生成句法分析树" class="md-nav__link">
      十八-生成句法分析树
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../19.understand/" title="十九-机器人是怎么理解“日后再说”的" class="md-nav__link">
      十九-机器人是怎么理解“日后再说”的
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../20.pos-base-method/" title="二十-语义角色标注" class="md-nav__link">
      二十-语义角色标注
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../21.tf-idf/" title="二十一-隐含语义索引模型" class="md-nav__link">
      二十一-隐含语义索引模型
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../22.artificial-neural-network/" title="二十二-人工神经网络" class="md-nav__link">
      二十二-人工神经网络
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../23.cnn/" title="二十三-用CNN做深度学习" class="md-nav__link">
      二十三-用CNN做深度学习
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../24.nlp-deep-learning/" title="二十四-将深度学习应用到NLP" class="md-nav__link">
      二十四-将深度学习应用到NLP
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../25.word2vec/" title="二十五-word2vec的实现原理" class="md-nav__link">
      二十五-word2vec的实现原理
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../26.rnn/" title="二十六-递归神经网络(RNN)" class="md-nav__link">
      二十六-递归神经网络(RNN)
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../27.auto-faq/" title="二十七-自动问答" class="md-nav__link">
      二十七-自动问答
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../28.subtitle-corpus/" title="二十八-基于美剧字幕的聊天语料库建设" class="md-nav__link">
      二十八-基于美剧字幕的聊天语料库建设
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../29.corpus-1g/" title="二十九-近1GB的三千万聊天语料" class="md-nav__link">
      二十九-近1GB的三千万聊天语料
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../30.tiny-rabbit/" title="三十-第一版聊天机器人小二兔" class="md-nav__link">
      三十-第一版聊天机器人小二兔
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../31.directive/" title="三十一-把网站流量导向小二兔" class="md-nav__link">
      三十一-把网站流量导向小二兔
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../32.word-vector/" title="三十二-用影视剧字幕语料库生成词向量" class="md-nav__link">
      三十二-用影视剧字幕语料库生成词向量
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../33.lstm-rnn/" title="三十三-LSTM-RNN—有记忆的神经网络" class="md-nav__link">
      三十三-LSTM-RNN—有记忆的神经网络
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../34.torch/" title="三十四-深度学习框架torch" class="md-nav__link">
      三十四-深度学习框架torch
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../35.lstm-learning/" title="三十五-一学会甄嬛体" class="md-nav__link">
      三十五-一学会甄嬛体
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../36.tensorflow-session-graph/" title="三十六-tensorflow的session和graph" class="md-nav__link">
      三十六-tensorflow的session和graph
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../37.tensorflow-lr/" title="三十七-tensorflow中的线性回归" class="md-nav__link">
      三十七-tensorflow中的线性回归
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="toc">
    
    
      <label class="md-nav__link md-nav__link--active" for="toc">
        三十八-聊天机器人构建流程
      </label>
    
    <a href="./" title="三十八-聊天机器人构建流程" class="md-nav__link md-nav__link--active">
      三十八-聊天机器人构建流程
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
  
    <label class="md-nav__title" for="toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#seq2seq" title="seq2seq模型原理" class="md-nav__link">
    seq2seq模型原理
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_1" title="语料准备工作" class="md-nav__link">
    语料准备工作
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_2" title="训练词向量" class="md-nav__link">
    训练词向量
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" title="创建模型" class="md-nav__link">
    创建模型
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_4" title="训练模型" class="md-nav__link">
    训练模型
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_5" title="效果预测" class="md-nav__link">
    效果预测
  </a>
  
</li>
      
      
      
    </ul>
  
</nav>
    
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../39.gpu-server/" title="三十九-搭建一台GPU共享云服务" class="md-nav__link">
      三十九-搭建一台GPU共享云服务
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../40.video-knowledge-point/" title="四十-视频之开篇宣言与知识点" class="md-nav__link">
      四十-视频之开篇宣言与知识点
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../41.video-python/" title="四十一-视频之环境搭建与python基础" class="md-nav__link">
      四十一-视频之环境搭建与python基础
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../42.practice/" title="四十二-从理论到实践开发聊天机器人1" class="md-nav__link">
      四十二-从理论到实践开发聊天机器人1
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../43.practice2/" title="四十三-从理论到实践开发聊天机器人2" class="md-nav__link">
      四十三-从理论到实践开发聊天机器人2
    </a>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
  
    <label class="md-nav__title" for="toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#seq2seq" title="seq2seq模型原理" class="md-nav__link">
    seq2seq模型原理
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_1" title="语料准备工作" class="md-nav__link">
    语料准备工作
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_2" title="训练词向量" class="md-nav__link">
    训练词向量
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" title="创建模型" class="md-nav__link">
    创建模型
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_4" title="训练模型" class="md-nav__link">
    训练模型
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_5" title="效果预测" class="md-nav__link">
    效果预测
  </a>
  
</li>
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                  <h1>三十八-聊天机器人构建流程</h1>
                
                <p>tensorflow自带的seq2seq模型基于one-hot的词嵌入，每个词用一个数字代替不足以表示词与词之间的关系，word2vec通过多维向量来做词嵌入，能够表示出词之间的关系，比如：男-女&asymp;王子-公主。基于seq2seq的思想，利用多维词向量来实现模型，预期会有更高的准确性。 </p>
<h3 id="seq2seq">seq2seq模型原理<a class="headerlink" href="#seq2seq" title="Permanent link">&para;</a></h3>
<p>主要参考<a href="http://cn.arxiv.org/pdf/1409.3215.pdf">《Sequence to Sequence Learning with Neural Networks》</a>这篇论文，核心思想如下图：</p>
<p>ABC是输入语句，WXYZ是输出语句，EOS是标识一句话结束，图中的训练单元是lstm，lstm的特点是有长短时记忆，所以能够根据输入的多个字来确定后面的多个字，有关lstm的知识可以参考《http://deeplearning.net/tutorial/lstm.html》</p>
<p>上面的模型中编码器和解码器共用了同一个lstm层，也就是共享了参数，牛人们尝试把他们分开像https://github.com/farizrahman4u/seq2seq中提到的样子：</p>
<p><img alt="farizrahman4u-seq2seq" src="../farizrahman4u-seq2seq.png" /></p>
<p>其中绿色是编码器，黄色是解码器，橙色的箭头传递的是lstm层的状态信息也就是记忆信息，编码器唯一传给解码器的就是这个状态信息</p>
<p>我们看到解码器每一时序的输入都是前一个时序的输出，从整体上来看就是：我通过不同时序输入“How are you <EOL>”，模型就能自动一个字一个字的输出“W I am fine <EOL>”，这里的W是一个特殊的标识，它既是编码器最后的输出，同时又是解码器的一个触发信号</p>
<p>那么我们训练的时候输入的X,Y应该是什么呢？X="How are you <EOL>"，Y="W I am fine <EOL>"?</p>
<p>这是不行的，因为在解码器还没有训练出靠谱的参数之前，我们无法保证第一个时序的输出就是“I”，那么传给第二个时序的输入就不一定是I，同样第三、四个时序的输入就无法保证是am和fine，那么是无法训练出想要的模型的</p>
<p>我们要这样来做：我们直接把解码器中每一时序的输入强制改为"W I am fine"，也就是把这部分从我们训练样本的输入X中传过来，而Y依然是预测输出的"W I am fine <EOL>"，这样训练出来的模型就是我们设计的编码器解码器模型了</p>
<p>那么在使用训练好的模型做预测的时候，我们改变处理方式：在解码时以前一时序的输出为输入做预测，这样就能输出我们希望输出的"W I am fine <EOL>"了</p>
<p>基于以上的原理，下面开始我们的工程实践</p>
<h3 id="_1">语料准备工作<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h3>
<p>准备至少300w的聊天语料用于词向量的训练和seq2seq模型的训练，语料越丰富训练出来的词向量质量越好，如果想通过影视剧字幕来获取语料可以参考<a href="../29.corpus-1g">《自己动手做聊天机器人 二十九-重磅：近1GB的三千万聊天语料供出》</a></p>
<p>获取到原始语料后需要做一些加工处理，首先需要做切词，方法如下：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>python word_segment.py ./corpus.raw ./corpus.segment
</pre></div>
</td></tr></table>

<p>其中word_segment.py是我写的切词工具，仅供参考</p>
<p>之后要把切词好的文件转成“|”分隔的问答对，如下：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>cat ./corpus.segment <span class="p">|</span> awk <span class="s1">&#39;{if(last!=&quot;&quot;)print last&quot;|&quot;$0;last=$0}&#39;</span> <span class="p">|</span> sed <span class="s1">&#39;s/| /|/g&#39;</span> &gt; ./corpus.segment.pair
</pre></div>
</td></tr></table>

<p>这样语料准备工作就齐全了</p>
<h3 id="_2">训练词向量<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h3>
<p>我们直接利用google的word2vec来训练词向量，如下：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>word2vec -train ./corpus.segment -output vectors.bin -cbow <span class="m">1</span> -size <span class="m">200</span> -window <span class="m">8</span> -negative <span class="m">25</span> -hs <span class="m">0</span> -sample 1e-5 -threads <span class="m">20</span> -binary <span class="m">1</span> -iter <span class="m">15</span>
</pre></div>
</td></tr></table>

<p>其中corpus.raw是原始语料数据，vectors.bin是生成的词向量二进制文件</p>
<p>了解word2vec的原理请见《自己动手做聊天机器人 二十五-google的文本挖掘深度学习工具word2vec的实现原理》</p>
<p>生成的词向量二进制加载方法可以参考我写的：word_vectors_loader.py</p>
<h3 id="_3">创建模型<a class="headerlink" href="#_3" title="Permanent link">&para;</a></h3>
<p>下面就是重点的模型创建过程，这里面我们直接使用tensorflow+tflearn库来实现：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># 首先我们为输入的样本数据申请变量空间，如下。</span>
<span class="c1"># 其中self.max_seq_len是指一个切好词的句子最多包含多少个词，</span>
<span class="c1"># self.word_vec_dim是词向量的维度，这里面shape指定了输入数据是不确定数量的样本，</span>
<span class="c1"># 每个样本最多包含max_seq_len*2个词，每个词用word_vec_dim维浮点数表示。</span>
<span class="c1"># 这里面用2倍的max_seq_len是因为我们训练是输入的X既要包含question句子又要包含answer句子</span>
<span class="n">input_data</span> <span class="o">=</span> <span class="n">tflearn</span><span class="o">.</span><span class="n">input_data</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_seq_len</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">word_vec_dim</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;XY&quot;</span><span class="p">)</span>
<span class="c1"># 然后我们将输入的所有样本数据的词序列切出前max_seq_len个，也就是question句子部分，作为编码器的输入</span>
<span class="n">encoder_inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_seq_len</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">word_vec_dim</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;enc_in&quot;</span><span class="p">)</span>
<span class="c1"># 再取出后max_seq_len-1个，也就是answer句子部分，作为解码器的输入。</span>
<span class="c1"># 注意，这里只取了max_seq_len-1个，是因为还要在前面拼上一组GO标识来告诉解码器我们要开始解码了，</span>
<span class="c1"># 也就是下面加上go_inputs拼成最终的go_inputs</span>
<span class="n">decoder_inputs_tmp</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_seq_len</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_seq_len</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">word_vec_dim</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;dec_in_tmp&quot;</span><span class="p">)</span>
<span class="n">go_inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">decoder_inputs_tmp</span><span class="p">)</span>
<span class="n">go_inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="n">go_inputs</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">word_vec_dim</span><span class="p">])</span>
<span class="n">decoder_inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="n">go_inputs</span><span class="p">,</span> <span class="n">decoder_inputs_tmp</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;dec_in&quot;</span><span class="p">)</span>
<span class="c1"># 之后开始编码过程，返回的encoder_output_tensor展开成tflearn.regression回归可以识别的形如(?, 1, 200)的向量；返回的states后面传入给解码器</span>
<span class="p">(</span><span class="n">encoder_output_tensor</span><span class="p">,</span> <span class="n">states</span><span class="p">)</span> <span class="o">=</span> <span class="n">tflearn</span><span class="o">.</span><span class="n">lstm</span><span class="p">(</span><span class="n">encoder_inputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">word_vec_dim</span><span class="p">,</span> <span class="n">return_state</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">scope</span><span class="o">=</span><span class="s1">&#39;encoder_lstm&#39;</span><span class="p">)</span>
<span class="n">encoder_output_sequence</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">pack</span><span class="p">([</span><span class="n">encoder_output_tensor</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># 取出decoder_inputs的第一个词，也就是GO</span>
<span class="n">first_dec_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="n">decoder_inputs</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">word_vec_dim</span><span class="p">])</span>
<span class="c1"># 将其输入到解码器中，如下，解码器的初始化状态为编码器生成的states，</span>
<span class="c1"># 注意：这里的scope=&#39;decoder_lstm&#39;是为了下面重用同一个解码器</span>
<span class="n">decoder_output_tensor</span> <span class="o">=</span> <span class="n">tflearn</span><span class="o">.</span><span class="n">lstm</span><span class="p">(</span><span class="n">first_dec_input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">word_vec_dim</span><span class="p">,</span> <span class="n">initial_state</span><span class="o">=</span><span class="n">states</span><span class="p">,</span> <span class="n">return_seq</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">reuse</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">scope</span><span class="o">=</span><span class="s1">&#39;decoder_lstm&#39;</span><span class="p">)</span>
<span class="c1"># 暂时先将解码器的第一个输出存到decoder_output_sequence_list中供最后一起输出</span>
<span class="n">decoder_output_sequence_single</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">pack</span><span class="p">([</span><span class="n">decoder_output_tensor</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">decoder_output_sequence_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">decoder_output_tensor</span><span class="p">]</span>
<span class="c1"># 接下来我们循环max_seq_len-1次，不断取decoder_inputs的一个个词向量作为下一轮解码器输入，</span>
<span class="c1"># 并将结果添加到decoder_output_sequence_list中，</span>
<span class="c1"># 这里面的reuse=True, scope=&#39;decoder_lstm&#39;说明和上面第一次解码用的是同一个lstm层</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_seq_len</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
   <span class="n">next_dec_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="n">decoder_inputs</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">word_vec_dim</span><span class="p">])</span>
   <span class="n">decoder_output_tensor</span> <span class="o">=</span> <span class="n">tflearn</span><span class="o">.</span><span class="n">lstm</span><span class="p">(</span><span class="n">next_dec_input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">word_vec_dim</span><span class="p">,</span> <span class="n">return_seq</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">reuse</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">scope</span><span class="o">=</span><span class="s1">&#39;decoder_lstm&#39;</span><span class="p">)</span>
   <span class="n">decoder_output_sequence_single</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">pack</span><span class="p">([</span><span class="n">decoder_output_tensor</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
   <span class="n">decoder_output_sequence_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">decoder_output_tensor</span><span class="p">)</span>
<span class="c1"># 下面我们把编码器第一个输出和解码器所有输出拼接起来，作为tflearn.regression回归的输入</span>
<span class="n">decoder_output_sequence</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">pack</span><span class="p">(</span><span class="n">decoder_output_sequence_list</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">real_output_sequence</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="n">encoder_output_sequence</span><span class="p">,</span> <span class="n">decoder_output_sequence</span><span class="p">])</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">tflearn</span><span class="o">.</span><span class="n">regression</span><span class="p">(</span><span class="n">real_output_sequence</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;sgd&#39;</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;mean_square&#39;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tflearn</span><span class="o">.</span><span class="n">DNN</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<p>至此模型创建完成，让我们汇总一下里面的思想：</p>
<ol>
<li>训练输入的X、Y分别是编码器解码器的输入和预测的输出；</li>
<li>X切分两半，前一半是编码器输入，后一半是解码器输入；</li>
<li>编码解码器输出的预测值用Y做回归训练</li>
<li>训练时通过样本的真实值作为解码器输入，实际预测时将不会有上图中WXYZ部分，因此上一时序的输出将作为下一时序的输入(后面会详述预测的实现)</li>
</ol>
<h3 id="_4">训练模型<a class="headerlink" href="#_4" title="Permanent link">&para;</a></h3>
<p>下面我们来实例化模型并喂数据做训练，如下：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainXY</span><span class="p">,</span> <span class="n">trainY</span><span class="p">,</span> <span class="n">n_epoch</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">snapshot_epoch</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;./model/model&#39;</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<p>这里的trainXY和trainY通过加载上面我们准备的语料来赋值</p>
<p>首先我们加载词向量并存到word_vector_dict中，然后读取语料文件并挨个词查word_vector_dict并赋值向量给question_seq和answer_seq，如下：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">init_seq</span><span class="p">(</span><span class="n">input_file</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;读取切好词的文本文件，加载全部词序列</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">file_object</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">input_file</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span>
    <span class="n">vocab_dict</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
        <span class="n">question_seq</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">answer_seq</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">line</span> <span class="o">=</span> <span class="n">file_object</span><span class="o">.</span><span class="n">readline</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">line</span><span class="p">:</span>
            <span class="n">line_pair</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;|&#39;</span><span class="p">)</span>
            <span class="n">line_question</span> <span class="o">=</span> <span class="n">line_pair</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">line_answer</span> <span class="o">=</span> <span class="n">line_pair</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">line_question</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">word_vector_dict</span><span class="o">.</span><span class="n">has_key</span><span class="p">(</span><span class="n">word</span><span class="p">):</span>
                    <span class="n">question_seq</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word_vector_dict</span><span class="p">[</span><span class="n">word</span><span class="p">])</span>
            <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">line_answer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">word_vector_dict</span><span class="o">.</span><span class="n">has_key</span><span class="p">(</span><span class="n">word</span><span class="p">):</span>
                    <span class="n">answer_seq</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word_vector_dict</span><span class="p">[</span><span class="n">word</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">break</span>
        <span class="n">question_seqs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">question_seq</span><span class="p">)</span>
        <span class="n">answer_seqs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">answer_seq</span><span class="p">)</span>
    <span class="n">file_object</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</td></tr></table>

<p>有了question_seq和answer_seq，我们来构造trainXY和trainY，如下：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>    <span class="k">def</span> <span class="nf">generate_trainig_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">xy_data</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">y_data</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">question_seqs</span><span class="p">)):</span>
            <span class="n">question_seq</span> <span class="o">=</span> <span class="n">question_seqs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">answer_seq</span> <span class="o">=</span> <span class="n">answer_seqs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">question_seq</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_seq_len</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">answer_seq</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_seq_len</span><span class="p">:</span>
                <span class="n">sequence_xy</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">word_vec_dim</span><span class="p">)]</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_seq_len</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">question_seq</span><span class="p">))</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="nb">reversed</span><span class="p">(</span><span class="n">question_seq</span><span class="p">))</span>
                <span class="n">sequence_y</span> <span class="o">=</span> <span class="n">answer_seq</span> <span class="o">+</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">word_vec_dim</span><span class="p">)]</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_seq_len</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">answer_seq</span><span class="p">))</span>
                <span class="n">sequence_xy</span> <span class="o">=</span> <span class="n">sequence_xy</span> <span class="o">+</span> <span class="n">sequence_y</span>
                <span class="n">sequence_y</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">word_vec_dim</span><span class="p">)]</span> <span class="o">+</span> <span class="n">sequence_y</span>
                <span class="n">xy_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sequence_xy</span><span class="p">)</span>
                <span class="n">y_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sequence_y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">xy_data</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_data</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<p>构造了训练数据也创建好了模型，训练的效果如下：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="o">[</span>root@centos <span class="c1">#] python my_seq2seq_v2.py train</span>
begin load vectors
<span class="nv">words</span> <span class="o">=</span> <span class="m">70937</span>
<span class="nv">size</span> <span class="o">=</span> <span class="m">200</span>
load vectors finish
---------------------------------
Run id: 9PZWKM
Log directory: /tmp/tflearn_logs/
---------------------------------
Training samples: <span class="m">368</span>
Validation samples: <span class="m">0</span>
--
Training Step: <span class="m">47</span>  <span class="p">|</span> total loss: <span class="m">0</span>.62260
<span class="p">|</span> SGD <span class="p">|</span> epoch: <span class="m">001</span> <span class="p">|</span> loss: <span class="m">0</span>.62260 -- iter: <span class="m">047</span>/368
</pre></div>
</td></tr></table>

<p>最终会生成./model/model模型文件</p>
<h3 id="_5">效果预测<a class="headerlink" href="#_5" title="Permanent link">&para;</a></h3>
<p>训练好模型，我们希望能输入一句话来预测一下回答，如下：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">predict</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">testXY</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<p>因为我们只有question没有answer，所以testXY中是没有Y部分的，所以需要在程序中做一些改变，即用上一句的输出作为下一句的输入，如下：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_seq_len</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
   <span class="c1"># next_dec_input = tf.slice(decoder_inputs, [0, i+1, 0], [-1, 1, self.word_vec_dim])这里改成下面这句</span>
   <span class="n">next_dec_input</span> <span class="o">=</span> <span class="n">decoder_output_sequence_single</span>
   <span class="n">decoder_output_tensor</span> <span class="o">=</span> <span class="n">tflearn</span><span class="o">.</span><span class="n">lstm</span><span class="p">(</span><span class="n">next_dec_input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">word_vec_dim</span><span class="p">,</span> <span class="n">return_seq</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">reuse</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">scope</span><span class="o">=</span><span class="s1">&#39;decoder_lstm&#39;</span><span class="p">)</span>
   <span class="n">decoder_output_sequence_single</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">pack</span><span class="p">([</span><span class="n">decoder_output_tensor</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
   <span class="n">decoder_output_sequence_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">decoder_output_tensor</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<p>因为词向量是多维浮点数，预测出的词向量需要通过余弦相似度来匹配，余弦相似度匹配方法如下：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">vector2word</span><span class="p">(</span><span class="n">vector</span><span class="p">):</span>
    <span class="n">max_cos</span> <span class="o">=</span> <span class="o">-</span><span class="mi">10000</span>
    <span class="n">match_word</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">word_vector_dict</span><span class="p">:</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">word_vector_dict</span><span class="p">[</span><span class="n">word</span><span class="p">]</span>
        <span class="n">cosine</span> <span class="o">=</span> <span class="n">vector_cosine</span><span class="p">(</span><span class="n">vector</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">cosine</span> <span class="o">&gt;</span> <span class="n">max_cos</span><span class="p">:</span>
            <span class="n">max_cos</span> <span class="o">=</span> <span class="n">cosine</span>
            <span class="n">match_word</span> <span class="o">=</span> <span class="n">word</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">match_word</span><span class="p">,</span> <span class="n">max_cos</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<p>其中的vector_cosine实现如下：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7
8
9</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">vector_cosine</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="n">v2</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">v1</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">v2</span><span class="p">):</span>
        <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">sqrtlen1</span> <span class="o">=</span> <span class="n">vector_sqrtlen</span><span class="p">(</span><span class="n">v1</span><span class="p">)</span>
    <span class="n">sqrtlen2</span> <span class="o">=</span> <span class="n">vector_sqrtlen</span><span class="p">(</span><span class="n">v2</span><span class="p">)</span>
    <span class="n">value</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">item1</span><span class="p">,</span> <span class="n">item2</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="n">v2</span><span class="p">):</span>
        <span class="n">value</span> <span class="o">+=</span> <span class="n">item1</span> <span class="o">*</span> <span class="n">item2</span>
    <span class="k">return</span> <span class="n">value</span> <span class="o">/</span> <span class="p">(</span><span class="n">sqrtlen1</span><span class="o">*</span><span class="n">sqrtlen2</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<p>其中的vector_sqrtlen实现如下：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">vector_sqrtlen</span><span class="p">(</span><span class="n">vector</span><span class="p">):</span>
    <span class="nb">len</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">vector</span><span class="p">:</span>
        <span class="nb">len</span> <span class="o">+=</span> <span class="n">item</span> <span class="o">*</span> <span class="n">item</span>
    <span class="nb">len</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="nb">len</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">len</span>
</pre></div>
</td></tr></table>

<p>预测效果如下：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>输入是“真 讨厌”
</pre></div>
</td></tr></table>

<p>预测结果：</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="o">[</span>root@centos <span class="c1">#] python my_seq2seq_v2.py test test.data</span>
begin load vectors
<span class="nv">words</span> <span class="o">=</span> <span class="m">70937</span>
<span class="nv">size</span> <span class="o">=</span> <span class="m">200</span>
load vectors finish
predict answer
竟然 <span class="m">0</span>.796628661264 <span class="m">8</span>.13188244428
是 <span class="m">0</span>.361905373571 <span class="m">4</span>.72316883181
你 <span class="m">0</span>.416023172832 <span class="m">3</span>.78265507983
啊 <span class="m">0</span>.454288467277 <span class="m">3</span>.13229596833
不是 <span class="m">0</span>.424590214456 <span class="m">2</span>.90688231062
你 <span class="m">0</span>.489174557107 <span class="m">2</span>.62733802498
啊 <span class="m">0</span>.501460288258 <span class="m">2</span>.87990178439
你 <span class="m">0</span>.560230783333 <span class="m">3</span>.09066126524
</pre></div>
</td></tr></table>

<p>输出的第一列是预测的每个时序产生的词，第二列是预测输出向量和最近的词向量的余弦相似度，第三列是预测向量的欧氏距离</p>
<p>因为我们设计的max_seq_len是定长8，所以输出的序列最后会多余一些字，可以根据余弦相似度或者其他指标设定一个阈值来截断</p>
<p>以上列出的是部分代码，全部代码分享在my_seq2seq_v2.py欢迎点击观看</p>
                
                  
                
              
              
                
              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../37.tensorflow-lr/" title="三十七-tensorflow中的线性回归" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                三十七-tensorflow中的线性回归
              </span>
            </div>
          </a>
        
        
          <a href="../39.gpu-server/" title="三十九-搭建一台GPU共享云服务" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                三十九-搭建一台GPU共享云服务
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        powered by
        <a href="http://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
        
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/application.6cdc17f0.js"></script>
      
      <script>app.initialize({version:"0.17.2",url:{base:".."}})</script>
      
    
    
      
    
  </body>
</html>